{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn                 \n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from model.ViT import ViT, HopfieldViT\n",
    "from model import *\n",
    "# Define the Vision Transformer model\n",
    "\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "# auto reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# Define the Vision Transformer model\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, num_classes, embed_dim, dim, num_heads, img_size, patch_size, in_channels=3):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "        self.patch_embedding = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.positional_embedding = nn.Parameter(torch.randn(1, self.num_patches, embed_dim))\n",
    "        self.hopfield = KHopfield(N=dim, n=embed_dim * self.num_patches)\n",
    "        self.fc = nn.Linear(embed_dim * self.num_patches, num_classes)\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.patch_embedding(x)  # (batch_size, embed_dim, num_patches_h, num_patches_w)\n",
    "        x2 = x1.permute(0, 2, 3, 1)  # (batch_size, num_patches_h, num_patches_w, embed_dim)\n",
    "        x3 = x2.reshape(x2.size(0), -1, x2.size(-1))  # (batch_size, num_patches, embed_dim)\n",
    "        \n",
    "        x4 = x3 + self.positional_embedding  # Add positional embedding\n",
    "        # combine second and third dimension\n",
    "        x5 = x4.flatten(1, 2)\n",
    "        x6 = self.hopfield(x5, self.num_heads)\n",
    "        x7 = x6.mean(dim=2)  # Global average pooling\n",
    "        x8 = self.fc(x7)\n",
    "        return x8\n",
    "    \n",
    "    def to(self, device):\n",
    "        super(VisionTransformer, self).to(device)\n",
    "        self.hopfield = self.hopfield.to(device)\n",
    "        return self\n",
    "    \n",
    "# Uses #num_heads k=1 hopfield networks, rather than k=num_heads-hopfield networks\n",
    "class VisionTransformerV(nn.Module):\n",
    "    def __init__(self, num_classes, embed_dim, dim, num_heads, img_size, patch_size, in_channels=3):\n",
    "        super(VisionTransformerV, self).__init__()\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "        self.patch_embedding = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.positional_embedding = nn.Parameter(torch.randn(1, self.num_patches, embed_dim))\n",
    "\n",
    "        self.hopfields = nn.ModuleList([KHopfield(N=dim, n=embed_dim * self.num_patches) for _ in range(num_heads)])\n",
    "        self.fc = nn.Linear(embed_dim * self.num_patches, num_classes)\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.patch_embedding(x)  # (batch_size, embed_dim, num_patches_h, num_patches_w)\n",
    "        x2 = x1.permute(0, 2, 3, 1)  # (batch_size, num_patches_h, num_patches_w, embed_dim)\n",
    "        x3 = x2.reshape(x2.size(0), -1, x2.size(-1))  # (batch_size, num_patches, embed_dim)\n",
    "        \n",
    "        x4 = x3 + self.positional_embedding  # Add positional embedding\n",
    "        # combine second and third dimension\n",
    "        x5 = x4.flatten(1, 2)\n",
    "        x6 = [self.hopfields[i](x5, 1) for i in range(self.num_heads)]\n",
    "        # take average of all heads\n",
    "        x6 = torch.stack(x6, dim=2).squeeze()\n",
    "        x7 = x6.mean(dim=2)  # Global average pooling\n",
    "        x8 = self.fc(x7)\n",
    "        return x8\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the Vision Transformer model\n",
    "# class VisionTransformer(nn.Module):\n",
    "#     def __init__(self, num_classes, embed_dim, num_heads, num_layers, img_size, patch_size):\n",
    "#         super(VisionTransformer, self).__init__()\n",
    "#         num_patches = (img_size // patch_size) ** 2\n",
    "#         self.patch_embedding = nn.Conv2d(3, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "#         self.positional_embedding = nn.Parameter(torch.randn(1, num_patches + 1, embed_dim))\n",
    "#         self.transformer = nn.Transformer(\n",
    "#             d_model=embed_dim,\n",
    "#             nhead=num_heads,\n",
    "#             num_encoder_layers=num_layers,\n",
    "#             dim_feedforward=2048,\n",
    "#             dropout=0.1,\n",
    "#         )\n",
    "#         self.fc = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.patch_embedding(x)  # (batch_size, embed_dim, num_patches_h, num_patches_w)\n",
    "#         x = x.permute(0, 2, 3, 1)  # (batch_size, num_patches_h, num_patches_w, embed_dim)\n",
    "#         x = x.reshape(x.size(0), -1, x.size(-1))  # (batch_size, num_patches, embed_dim)\n",
    "#         x = torch.cat([self.positional_embedding, x], dim=1)\n",
    "#         x = self.transformer(x)\n",
    "#         x = x.mean(dim=1)  # Global average pooling\n",
    "#         x = self.fc(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "num_classes = 10\n",
    "img_size = 32  # Assuming CIFAR-10 image size\n",
    "\n",
    "#mnist\n",
    "\n",
    "patch_size = 16  # Adjust this based on your preference\n",
    "\n",
    "datast = 'mnist'\n",
    "dataset = 'cifar'\n",
    "num_heads = 4\n",
    "\n",
    "if dataset == 'mnist':\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    train_dataset = torchvision.datasets.MNIST(root='~/data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(root='~/data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "    img_size = 28\n",
    "    in_channels = 1\n",
    "    num_classes = 10\n",
    "else:\n",
    "    train_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                                    transforms.RandomCrop(32, padding=4), transforms.RandomHorizontalFlip()])\n",
    "\n",
    "    val_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root='~/data', train=True, transform=train_transform, download=True)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root='~/data', train=False, transform=val_transform, download=True)\n",
    "    img_size = 32\n",
    "    in_channels = 3\n",
    "    num_classes = 10\n",
    "\n",
    "# Data preprocessing\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = VisionTransformer(\n",
    "    num_classes = num_classes, \n",
    "    embed_dim = 256, \n",
    "    dim  = 1024,\n",
    "    num_heads = num_heads, \n",
    "    img_size = img_size, \n",
    "    patch_size = patch_size, \n",
    "    in_channels = in_channels,\n",
    ")\n",
    "modelV= VisionTransformerV(\n",
    "    num_classes = num_classes, \n",
    "    embed_dim = 256, \n",
    "    dim  = 1024,\n",
    "    num_heads = num_heads, \n",
    "    img_size = img_size, \n",
    "    patch_size = patch_size, \n",
    "    in_channels = in_channels,\n",
    ")\n",
    "\n",
    "embedding_dim = 2196\n",
    "num_heads = 8\n",
    "num_layers = 1\n",
    "patch_size = 16\n",
    "\n",
    "modelS = SimpleViT(\n",
    "    image_size = img_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = num_classes,\n",
    "    dim = 128,\n",
    "    depth = 2,\n",
    "    heads = 4,\n",
    "    mlp_dim = 512\n",
    ")\n",
    "\n",
    "patch_size= 4\n",
    "modelViT = ViT(\n",
    "    image_size = img_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = num_classes,\n",
    "    dim = 128,\n",
    "    depth = 2,\n",
    "    heads = 4,\n",
    "    mlp_dim = 512\n",
    ")\n",
    "\n",
    "\n",
    "patch_size= 4\n",
    "modelViT = ViT(\n",
    "    image_size = img_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = num_classes,\n",
    "    dim = 128,\n",
    "    depth = 2,\n",
    "    heads = 5,\n",
    "    mlp_dim = 512\n",
    ")\n",
    "\n",
    "modelHViT = HopfieldViT(\n",
    "    image_size = img_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = num_classes,\n",
    "    dim = 128,\n",
    "    depth = 2,\n",
    "    heads = 5,\n",
    "    mlp_dim = 512\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "modelV = modelV.to(device)\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       grad_fn=<SumBackward1>) torch.Size([256, 5, 65])\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       grad_fn=<SumBackward1>) torch.Size([256, 5, 65])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 10])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelViT(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16640, 65])\n",
      "torch.Size([16640, 65])\n",
      "sum of last_ssm tensor(0., grad_fn=<SumBackward0>)\n",
      "sum of last_ssm tensor([65., 65., 65.,  ..., 65., 65., 65.], grad_fn=<SumBackward1>)\n",
      "sum of last_ssm tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)\n",
      "sum of last_ssm tensor([65., 65., 65.,  ..., 65., 65., 65.], grad_fn=<SumBackward1>)\n",
      "sum of last_ssm tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)\n",
      "torch.Size([16640, 65, 5])\n",
      "tensor([[  0.,  65., -65.,  65., -65.],\n",
      "        [  0.,  65., -65.,  65., -65.],\n",
      "        [  0.,  65., -65.,  65., -65.],\n",
      "        ...,\n",
      "        [  0.,  65., -65.,  65., -65.],\n",
      "        [  0.,  65., -65.,  65., -65.],\n",
      "        [  0.,  65., -65.,  65., -65.]], grad_fn=<SumBackward1>)\n",
      "torch.Size([16640, 65])\n",
      "torch.Size([16640, 65])\n",
      "sum of last_ssm tensor(0., grad_fn=<SumBackward0>)\n",
      "sum of last_ssm tensor([65., 65., 65.,  ..., 65., 65., 65.], grad_fn=<SumBackward1>)\n",
      "sum of last_ssm tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)\n",
      "sum of last_ssm tensor([65., 65., 65.,  ..., 65., 65., 65.], grad_fn=<SumBackward1>)\n",
      "sum of last_ssm tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)\n",
      "torch.Size([16640, 65, 5])\n",
      "tensor([[  0.,  65., -65.,  65., -65.],\n",
      "        [  0.,  65., -65.,  65., -65.],\n",
      "        [  0.,  65., -65.,  65., -65.],\n",
      "        ...,\n",
      "        [  0.,  65., -65.,  65., -65.],\n",
      "        [  0.,  65., -65.,  65., -65.],\n",
      "        [  0.,  65., -65.,  65., -65.]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 10])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelHViT(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-f7f7305d64f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLML2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graph3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/khopfield/model/lml2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         return LML_Function.apply(\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         )\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/khopfield/model/lml2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, x, N, eps, n_iter, branch, verbose)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mx_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "x = torch.randn(256, 5)\n",
    "print(x.shape)\n",
    "result = LML2(N = 5, n_iter = 200, eps = 1e-3)(x)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssm(x, k, beta):\n",
    "    # x in b x n\n",
    "    return LML2(N=k, n_iter = 200,eps = 1e-3)(beta * x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = torch.randn(256, 65, 65)\n",
    "result = ssm(x, 5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(result, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss: 1.6018: 100%|██████████| 196/196 [00:25<00:00,  7.67it/s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss: 1.6018, Val Accuracy: 46.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.6363: 100%|██████████| 196/196 [00:25<00:00,  7.69it/s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.6363, Val Accuracy: 50.6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] Loss: 1.3431:  95%|█████████▍| 186/196 [00:24<00:01,  7.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b1596f0c9115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch [{epoch + 1}/{num_epochs}] Loss: {loss.item():.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graph3/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graph3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "model = modelViT.to(device)\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # show loss in tqdm\n",
    "    model.train()\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for i, (images, labels) in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(f'Epoch [{epoch + 1}/{num_epochs}] Loss: {loss.item():.4f}')\n",
    "\n",
    "    # validate\n",
    "    accuracy = validate(model, test_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}] Loss: {loss.item():.4f}, Val Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "\n",
    "print('Training finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(0.8274, grad_fn=<CopyBackwards>)\n",
      "1\n",
      "tensor(0.7943, grad_fn=<CopyBackwards>)\n",
      "2\n",
      "tensor(0.7643, grad_fn=<CopyBackwards>)\n",
      "3\n",
      "tensor(0.7368, grad_fn=<CopyBackwards>)\n",
      "4\n",
      "tensor(0.7115, grad_fn=<CopyBackwards>)\n",
      "5\n",
      "tensor(0.6887, grad_fn=<CopyBackwards>)\n",
      "6\n",
      "tensor(0.6683, grad_fn=<CopyBackwards>)\n",
      "7\n",
      "tensor(0.6504, grad_fn=<CopyBackwards>)\n",
      "8\n",
      "tensor(0.6348, grad_fn=<CopyBackwards>)\n",
      "9\n",
      "tensor(0.6215, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.nn.Parameter(torch.randn(59, 16))\n",
    "\n",
    "hopfield = KHopfield(N=100, n=16 )\n",
    "\n",
    "# optimize the hopfield network\n",
    "optimizer = optim.Adam(hopfield.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    Y = hopfield(X, 4)\n",
    "    loss = torch.norm(Y)\n",
    "    loss.backward()\n",
    "    print(loss)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer 1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model and optimizer\n",
    "num_heads = 3\n",
    "\n",
    "\n",
    "model = VisionTransformer(\n",
    "    num_classes = num_classes, \n",
    "    embed_dim = 1024, \n",
    "    num_heads = num_heads, \n",
    "    img_size = img_size, \n",
    "    patch_size = patch_size, \n",
    "    in_channels = in_channels,\n",
    ")\n",
    "model = SimpleViT(\n",
    "    image_size = img_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = num_classes,\n",
    "    dim = 1024,\n",
    "    depth = 1,\n",
    "    heads = 4,\n",
    "    mlp_dim = 2048\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_and_data(\n",
    "        data = 'mnist',\n",
    "        model = 'hopfield',\n",
    "        batch_size = 256,\n",
    "        heads = 4,\n",
    "        dim=256,\n",
    "        embed_dim=1024):\n",
    "    if data == 'mnist':\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        train_dataset = torchvision.datasets.MNIST(root='~/data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "        test_dataset = torchvision.datasets.MNIST(root='~/data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "        img_size = 28\n",
    "        in_channels = 1\n",
    "        num_classes = 10\n",
    "\n",
    "    elif data  == 'cifar10':\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "        train_dataset = torchvision.datasets.CIFAR10(root='~/data', train=True, transform=transform, download=True)\n",
    "        test_dataset = torchvision.datasets.CIFAR10(root='~/data', train=False, transform=transform, download=True)\n",
    "        img_size = 32\n",
    "        in_channels = 3\n",
    "        num_classes = 10\n",
    "    else:\n",
    "        raise Exception('data not found')\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    patch_size = 16\n",
    "\n",
    "    if model == 'hopfield':\n",
    "        model = VisionTransformer(\n",
    "            num_classes = num_classes, \n",
    "            embed_dim = embed_dim, \n",
    "            dim = dim,\n",
    "            num_heads = heads, \n",
    "            img_size = img_size, \n",
    "            patch_size = patch_size, \n",
    "            in_channels = in_channels,\n",
    "        )\n",
    "    elif model == 'hopfieldV':\n",
    "        model = VisionTransformerV(\n",
    "            num_classes = num_classes, \n",
    "            embed_dim = embed_dim, \n",
    "            dim = dim,\n",
    "            num_heads = heads, \n",
    "            img_size = img_size, \n",
    "            patch_size = patch_size, \n",
    "            in_channels = in_channels,\n",
    "        )\n",
    "    elif model == 'vit':\n",
    "        model = SimpleViT(\n",
    "            image_size = img_size,\n",
    "            patch_size = patch_size,\n",
    "            num_classes = num_classes,\n",
    "            dim = dim,\n",
    "            depth = 1,\n",
    "            heads = heads,\n",
    "            mlp_dim = 1024\n",
    "        )\n",
    "    return model, train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(train_loader, test_loader, model, num_epochs=30, k=1):\n",
    "    # Initialize the model and optimizer\n",
    "    model = model.to(device)\n",
    "    learning_rate = 1e-3\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    val_accuracy = []\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # show loss in tqdm\n",
    "        model.train()\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        for i, (images, labels) in pbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.set_description(f'K: {k}, Epoch [{epoch + 1}/{num_epochs}] Loss: {loss.item():.4f}')\n",
    "\n",
    "        # validate\n",
    "        accuracy = validate(model, test_loader)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] Loss: {loss.item():.4f}, Val Accuracy: {accuracy:.4f}')\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    print('Training finished!')\n",
    "\n",
    "    return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model, train_loader, test_loader = get_model_and_data(data = 'cifar10', model = 'hopfieldV', batch_size = 256, heads = 4, dim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss: 1.7703:  69%|██████▉   | 135/196 [00:28<00:12,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss: 1.7718:  81%|████████  | 158/196 [00:33<00:07,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss: 1.7759: 100%|██████████| 196/196 [00:42<00:00,  4.66it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:00<00:27,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:01<00:26,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [00:01<00:11,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [00:02<00:16,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/40 [00:02<00:11,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [00:03<00:15,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [00:03<00:04,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [00:05<00:10,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 17/40 [00:05<00:06,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 18/40 [00:06<00:08,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26/40 [00:07<00:01,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [00:07<00:03,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [00:08<00:05,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 30/40 [00:08<00:02,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [00:09<00:03,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 34/40 [00:09<00:01,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 35/40 [00:10<00:01,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 36/40 [00:10<00:01,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 37/40 [00:11<00:01,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:12<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "Epoch [1/10] Loss: 1.7759, Val Accuracy: 37.1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.7572:   1%|          | 2/196 [00:01<01:27,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.6693:   4%|▎         | 7/196 [00:02<00:52,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.6940:   6%|▌         | 11/196 [00:04<00:52,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.7229:   7%|▋         | 13/196 [00:05<01:07,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.6652:   7%|▋         | 14/196 [00:05<01:30,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.7735:   8%|▊         | 15/196 [00:06<01:46,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.7192:  10%|▉         | 19/196 [00:08<01:03,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.7291:  11%|█         | 21/196 [00:09<01:10,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.8094:  12%|█▏        | 23/196 [00:10<01:14,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.7165:  13%|█▎        | 26/196 [00:11<01:02,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.7220:  14%|█▍        | 27/196 [00:12<01:23,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.6341:  15%|█▍        | 29/196 [00:13<01:19,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.6674:  16%|█▌        | 31/196 [00:14<01:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Loss: 1.7895:  17%|█▋        | 34/196 [00:15<01:13,  2.22it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a9044fc0ee24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_accuracy\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-8003deb5ca19>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(train_loader, test_loader, model)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graph3/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graph3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graph3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graph3/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graph3/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graph3/lib/python3.6/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graph3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graph3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/graph3/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_accuracy  = run_experiment(train_loader, test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.8465:  74%|███████▍  | 145/196 [00:12<00:05,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.8947:  80%|████████  | 157/196 [00:14<00:04,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.8947:  81%|████████  | 159/196 [00:14<00:04,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.8592:  83%|████████▎ | 163/196 [00:14<00:04,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 2.0062:  90%|█████████ | 177/196 [00:16<00:01, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.8696:  91%|█████████▏| 179/196 [00:16<00:02,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.9123:  92%|█████████▏| 180/196 [00:16<00:02,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.9561:  92%|█████████▏| 181/196 [00:17<00:02,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.7960:  93%|█████████▎| 182/196 [00:17<00:02,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.8889:  93%|█████████▎| 183/196 [00:17<00:02,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.9196:  94%|█████████▍| 184/196 [00:17<00:02,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.9212:  94%|█████████▍| 185/196 [00:17<00:02,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.7215:  95%|█████████▍| 186/196 [00:18<00:02,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.8627:  95%|█████████▌| 187/196 [00:18<00:02,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.8871:  96%|█████████▌| 188/196 [00:18<00:01,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.9203:  97%|█████████▋| 191/196 [00:19<00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.8725:  98%|█████████▊| 193/196 [00:19<00:00,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 1, Epoch [1/1] Loss: 1.9822: 100%|██████████| 196/196 [00:19<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:00<00:09,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:00<00:08,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [00:00<00:06,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [00:00<00:06,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/40 [00:01<00:06,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 9/40 [00:01<00:04,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 10/40 [00:01<00:04,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [00:02<00:05,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [00:02<00:04,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 14/40 [00:02<00:04,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 17/40 [00:02<00:03,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 18/40 [00:03<00:03,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 20/40 [00:03<00:03,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 22/40 [00:03<00:02,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [00:04<00:02,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26/40 [00:04<00:02,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [00:04<00:02,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [00:04<00:02,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 29/40 [00:04<00:02,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [00:05<00:01,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 33/40 [00:05<00:01,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 34/40 [00:05<00:01,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 35/40 [00:06<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 37/40 [00:06<00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:06<00:00,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "Epoch [1/1] Loss: 1.9822, Val Accuracy: 29.7500\n",
      "Training finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 2, Epoch [1/1] Loss: 1.6783:  81%|████████  | 159/196 [00:14<00:03, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 2, Epoch [1/1] Loss: 1.8000:  90%|█████████ | 177/196 [00:17<00:01, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 2, Epoch [1/1] Loss: 1.7893:  93%|█████████▎| 183/196 [00:17<00:02,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 2, Epoch [1/1] Loss: 1.8720:  98%|█████████▊| 192/196 [00:18<00:00,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K: 2, Epoch [1/1] Loss: 2.0308: 100%|██████████| 196/196 [00:19<00:00, 10.18it/s]\n",
      "  2%|▎         | 1/40 [00:00<00:15,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:00<00:14,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [00:01<00:09,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [00:01<00:08,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [00:02<00:03,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [00:03<00:01, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [00:04<00:01,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 35/40 [00:05<00:00,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 37/40 [00:05<00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:06<00:00,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML Warning: Did not converge.\n",
      "LML Warning: Did not converge.\n",
      "Epoch [1/1] Loss: 2.0308, Val Accuracy: 34.2100\n",
      "Training finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ks = [1, 4, 8, 16]\n",
    "ks = [1,2]\n",
    "df = pd.DataFrame(columns = ['k', 'accuracy', 'model', 'epoch'])\n",
    "data = 'cifar10'\n",
    "model_name = 'hopfield'\n",
    "for k in ks:\n",
    "    model, train_loader, test_loader = get_model_and_data(data = data, model = model_name, batch_size = 256, heads = k, dim=100)\n",
    "    val_accuracy  = run_experiment(train_loader, test_loader, model, num_epochs=1, k =k )\n",
    "    # add every val accuracy to dataframe\n",
    "    for i, acc in enumerate(val_accuracy):\n",
    "        df = df.append({'k': k, 'accuracy': acc, 'model': 'hopfield', 'epoch': i}, ignore_index=True)\n",
    "    \n",
    "    # save dataframe\n",
    "    df.to_csv(f'./results/{data}_{model_name}_heads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df rows\n",
    "import pandas as pd\n",
    "data = 'cifar10'\n",
    "model_name = 'hopfield'\n",
    "df = pd.read_csv(f'./results/{data}_{model_name}_heads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.75</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34.21</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  k  accuracy     model  epoch\n",
       "0           0  1     29.75  hopfield      0\n",
       "1           1  2     34.21  hopfield      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/cifar10_hopfield_heads.csv\n"
     ]
    }
   ],
   "source": [
    "print(f'./results/{data}_{model}_heads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'mnist'\n",
    "model = 'hopfield'\n",
    "df = pd.read_csv(f'./results/{data}_{model}_heads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15.41</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>17.31</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17.99</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>18.91</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17.94</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>505</td>\n",
       "      <td>16</td>\n",
       "      <td>49.78</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>506</td>\n",
       "      <td>16</td>\n",
       "      <td>50.14</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>507</td>\n",
       "      <td>16</td>\n",
       "      <td>51.12</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>508</td>\n",
       "      <td>16</td>\n",
       "      <td>52.14</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>509</td>\n",
       "      <td>16</td>\n",
       "      <td>53.08</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   k  accuracy     model  epoch\n",
       "0             0   4     15.41  hopfield      0\n",
       "1             1   4     17.31  hopfield      1\n",
       "2             2   4     17.99  hopfield      2\n",
       "3             3   4     18.91  hopfield      3\n",
       "4             4   4     17.94  hopfield      4\n",
       "..          ...  ..       ...       ...    ...\n",
       "505         505  16     49.78  hopfield     25\n",
       "506         506  16     50.14  hopfield     26\n",
       "507         507  16     51.12  hopfield     27\n",
       "508         508  16     52.14  hopfield     28\n",
       "509         509  16     53.08  hopfield     29\n",
       "\n",
       "[510 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcad1a2f3c8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABsHUlEQVR4nO2dd3hU1daH35NOEkjoLfTeka4UUURQpFguIApi1wuKguKngsRyFUTAQlFARaQoUqRJEwhIJ0gvIQkESChJSO+ZmfX9sROSQMpMCjCw3+c5T+b0vWcm66xZe+3fMkQEjUaj0dgvDre6ARqNRqMpGtqQazQajZ2jDblGo9HYOdqQazQajZ2jDblGo9HYOU4382YVKlSQ2rVr38xbajQajd1z4MCBSBGpmNf+m2rIa9eujb+//828pUaj0dg9hmGcy2+/Dq1oNBqNnaMNuUaj0dg52pBrNBqNnaMNuUaj0dg52pBrNBqNnaMNuUaj0dg52pBrNBqNnXNT88g1Go3mTiTNnEZsSiwxKTHEpqq/MSkxObY91+o56pWrVyL314Zco9FobCAyKZLlJ5fzx4k/OBZ+jNiUWJJNyfmeY2Bwr8+92pBrNBrNrSI6OZoVp1aw5PgS/j7zN2Yx06BcA/o06EO5UuXwcvXC280bL7eMv9ete7p44mCUXCRbG3KNRqPJhdiUWFYGrOT347+zKXgT6ZZ06paty7v3vcug5oNoVbkVhmHc6mYC2pBrNBoNACaLiaCoIPaH7WfpyaWsD1pPmjmNWl61eKvTWwxsNpC2VdveNsY7O9qQazSauwoRITQulKPhRzkWfuza35MRJ0k1pwJQvXR1RrQfwaBmg+hQvcNtabyzow25RqO5oxARopKjuJRwicsJl7mccJlL8ZcIjg6+ZrTjUuOuHV+9dHVaVG7BQ3Ueonml5rSs3JJWVVqVaEy7uNGGXKPR2CVBUUH8fux3zsWeyzLYCZe4knCFdEv6DceXdStL80rNebbFszSv1JwWlVvQrGIzypYqewtaX7xoQ67RaOwGs8XMX4F/MWP/DDYEb8DAoKJHRap4VqGqZ1WaVmxKVc+qVPGsoraVrnptn6eL520fIiks2pBrNJrbnojECH48+CPf+3/PudhzVCtdDd/7fXm57ctUK13tVjfvlqMNuUajuS0REfaG7WXG/hksOb6ENHMaD9R+gK8e/or+jfrj7Oh8q5t426ANuUajua1ITEvkt2O/MWP/DA5ePkhpl9K80uYVXm//Ok0rNr3VzbMaEeF87Hlqedcq8XtpQ67RaG45FrHgF+LH/MPzWXZyGQlpCTSv1JxZfWbxTItnKO1a+lY30WZGbxjN4mOLOTHiBOVKlSvRe2lDrtFobhnHw4/z65FfWXh0IaFxoZR2Kc3ApgMZ3no4XWp2sevByRfbvEi9cvUo61byWTHakGs0mpvKlYQrLD62mPmH53Pw8kEcDUd61e/FVz2/ol+jfpRyLnWrm1goRIQvd35JQloCnz74Kc0rNad5peY35d7akGs0mhLDIhbCE8MJjQvlZMRJFh9bzMbgjZjFTNuqbfm619cMbj6Yyp6Vb3VTi4xhGARHBxOXGodFLDd1QpE25BqNplBkzqA8H3ueC3EXuBB7gQtxFwiNC722HhYfRpo57do5NcrU4N373mVoq6F2NXCZH9vPbadGmRrUKVuHGY/OwMnBKWdIKCUSJB1KVS2xNmhDrtFocsUiFi4nXOZczDnOxZ7jXMw5QmJC1OuM9cT0xBznODk44VPGhxplatDJpxM1ytSghlcNapSpQS3vWrSs3PLmT32/eBGqVgXDgDVr4Jtv4LffoHx5WLcO5s2DuXOhdGnYtAlWrYKPP4ZyBQ9QJqQl8Pjvj9OrXi8WPblIpUSmx0P4dqjSExxdIHgOpF6FNl+VWBe1IddoNNeIT41nzr9z+PHgjwRFBeXwpgHKlSpHLa9aNCzfkJ51e1LLqxY1vWpeM9aVPSvfXhol27ZBz57KgD/YBVISICEezMlgSoIrYXDkMKQlgMkRTh6DP5bAlCnq/G++gQ0blHF3cgIRBIPDlw/TqkpLQk578pyxgveaxkNKBMlSEadLm3De8yT03AEVO0PtZyEtukS7aYhIid4gO+3atRN/f/+bdj+NRmMdlxMu8+3eb5m5fyaxqbF0rdmVe33upbZ3bWp517pmsPNLAzRZTFyIvUBFj4p4ungSHBXMLP9Z/Lf9f6lbti7Hwo/x4ZYP+aLHFzSt2BQRKZmslOBguHoVOnSA1FQY9x602QOy17rzBXBwACdP2GjAcTNMaApOpdn+gTdPJ/ThoRdf4IWGPTixdgTTVzfk+JfNof33zPjtP7z/hRMhB/wp1/A+1vxh4s/1rnw70xl398J3yTCMAyLSLq/92iPXaO5iTkWeYsquKcw/Mh+TxcSTTZ7k3fvepX319gWeG50czafbP6Vvw748UOcBDl0+RPs57Vk5eCX9GvUjKjmKGftn0KteL+qWrUtEYgQBkQG4OroCsOT4EkZvHM2O53dQp2wdIhIjMIuZKp5VCt8hERgwANzdYe9eMEdA900QHwRNPwTnMlZcwwLxwWBJJaxvRYYeeI7fQh8hrbRQp2E1uux046fKYI7dQrf1mxlU1huLBRz2v0bHmT8ztmJ/vGPOwKl9nB2ZwMakN3H7wQ2w4t6FRHvkGs1dyM7zO5m8azIrA1bi5uTGC61fYPS9o22qKRmeGE7j6Y35qf9PDGg8gNiUWJafXE6Puj2o6VWTTNuSl9f9z7l/mPPvHOb2m4uLowufbvuUCX4TiP2/WNwc3Nh3ch9iEsqXKg+oAscWseDm5AaQ5dGnp0N8PJQtq+LgqakqDGJYIOWKMsxulcDRLdd2iKjFISMidPUqlHUNxcHZDXGpwJUr4OVxgVQMvEv7qIMsJjAcITUFxAzOBljSITkVMIOzWd03BXAAXADXiuCUv1vu5uaGj48Pzs455QcK8si1Iddo7hIsYmF1wGq+3PUluy7sonyp8ozsMJIR7UdQ0aOiVddYfHQxfiF+/ND3B0CVQ/Ny8yqW9h0PP87esL28cM8LnD17lnSndFJdUmlRuQUAITEhxKbE0qpKq4z1s8SnJtDCtQacOUNsverg6qbak56gvHDDgNINchjQmBhluMtmzNM5fhxKlbJQt2o4uFXiVIADFbzicCyThJd7JRwMBxLTEnE0HHFzzv1hkCsWM1hSwZwKlhRwKQcZv0ZyQ0S4evUq8fHx1KlTJ8c+HVrRaO5y0s3pLD62mIk7JnIy8iR1vOvw3SPf8Xzr5/Fw8Sjw/Oyx7HOx5zh85TAJaQl4ungWmxEHaFapGc0qNQMgJSWFxo0b5/Dmq3lWo6J7RbBY4MwZyng6UsqzEnh4QYsWXI49gyXNgnOaA+lxV4h1ERxdy2K55E5qKlSrlYSD4UB4uBtmM7h4JOLo4EilSm6UcoyDpFDSDCcaN65AXCqcvhpKHcOZ8u7lrXqfbsDBERzcC/TCMzEMg/LlyxMREWH7rWw+Q6PR2AXJ6cnM3D+TBt814Lk/n8PF0YXFTy7m9BunGdlhpFXGKSwujB7ze7D5zGYA3rnvHXa/uBtPF091gDlNZX+UANeHZFws4OHiQXKqA1HpnpQz3KnsWZnLVwwCzjhTv1x96nqUI/xSKiGRtbA4e2HBAWdncHGB4KhgLsZfpHZtaNQIgqODuRJ/kYoVwbOcNwEmJy6lqHTK0i6laVS+UYlrpBTUZ2vRHrlGc4cRlxrH9/7fM3X3VK4kXuG+Gvcxs89MHqn/iNWGwmQx4eTgRHn38sSnxROdotLnnByymYywv8B/BJgS4J4pUGeoCmUUkcOHITlZOd4ODhAeDpdCzbQwTuDQojlRUU5cSqyCdyPliTo6qpC4Q2okrskXqFqhHFXcy+JWqq66YMaPhvjU2jg6OOKSEX5u4Fket9RwMKeAoxtVvevi7KB2GoZhV0Jd2iPXaO4QIpMi+WjrR9T6uhbv/f0erau0Ztvwbex4fgePNnjUaiP+v+3/494f78VsMePm5Ma+l/bxVNOnsg5Iugg7BsK2PuBYCjzrw57nYMtDEHfa5nYfPw6vvw6RkWr9wAEVx06Piof0dFxdwauMIFXUpJ6KFaFZs6xnRsUKQr2qoRhJF8ClLK7lauNWyvGG+5R2LY27c1aYo5RbBQwXbzCU8S7jWiaHzktISAjNm9uulfLhhx9So0YNPD09bT63sBTokRuG4QZsB1wzjl8qIhMMw6gD/AaUBw4AQ0UkLe8raTR3DhaxcDz8ODvO72DHhR2cjz2Pg+GAo+GIg+GQY3F0yNrmaDji5epFuVLlKFeqHGVLlc167Zb1uoxrmTwNr4ggCBaxYLaYuZJ4ha/3fM0PB34gKT2JJ5o8wftd3qddtTzHxm4gIDKAOmXr4OLoQoPyDWhfrT3JpuSc5dEsZgj6AQ6/rwbwWn4GTd4FBycImgOH3oO/WkCzD6Dp/+U5sHf2LHzwAYwZA+3aKaO9cCE8+yxUqACDB8PZQBOuIQFQtSpe1avj5eUEKD0Wl+w2WgQSz0FqJLhVBPea+f8qMKeqyTmlqqj2edbJ+9hC0rdvX0aOHEmDBg2K/dp5YU1oJRV4UEQSDMNwBnYYhrEOGA1ME5HfDMP4HngRmFWCbdVobhnJ6cnsD93LjtBd7Anehmn3To54JBLmBc2MyjwTWpZtbSuQ5KIMbOZiFnOOdZPFRGxKLFHJUSSbkvO8n6PhSCnnUpgtOc+3iAXhxkwzR8ORZ1o+w3ud37NZw+TfS//SbnY75vabywv3vMDAZgMZ2GxgzoOiD8O+V+HqXqjyELSfBaXrZ+1v8Cr49Id/R8NRXzi3GNp/D5W7YzLB9OnQujV07w6enrBjhzLY7dpBp04QHa1CJJhMuLs74eDiBHVqqYPfegsOHbqx4WJRWSEWkzLKDi4Fd9aSqtIE294L33xn9Xt05swZnnzySWbPnk379vnn2Hfq1Mnq6xYXBRpyUfmJCRmrzhmLAA8CQzK2/wL4og255g5BgoPxu7iLdSlHOXxiK3++488fPWF6R+jm0pBtsxPZ+8FzVHpzArXjHTFq1eL9Tj/C8y8oL9GKMEZyejLRKdFEJUcRnaz+Zl+STck3ePjXe/cOhgMuji480eQJ6pS13rvcH7afSwmX6NeoH/dUuYdpvabRt2HfGw80JSrDfGoauJaHexdA7SG5969UFei8COo8B/tfh80PQJ3nSG/8Fd9+W4E+fZQhr1gRLlzIOs0x08OOjYVu3eDdd6FtWyiT2wQaUYbbkq7yt0HlhztYWfbNwVWFUowbQy95ERAQwODBg5k3bx5ubm60bt061+P8/Pzw9va2+rrFiogUuACOwCGUQZ8EVACCsu2vARzL49xXAH/Av2bNmqLR3O6kJCfIxWplZFtNxOUTZ+k2+z7xG9hBdiycKFeTroqkp4v8/bfIxYvqBItFZPt2kYQEtb5ggUi3biLh4beuEwXQ45ce0nRGU7FYLHkfFLpa5M9aIgsR2fOySMpVq69/8XyifPDiFjEtcBFZWl6u7F0sFnM+9xIRiYoS6dNHZNs2OXHiRNZ2i0UkNUYkLkjkqr9I5H6R6GMiSZdEzKkFNyYlSiTmmHXHZuPs2bNSqVIladSokRw/ftymc0VEPDw8bD5HRHL2PQPAX/Kx0VZlrYiIGWhtGIY3sAJobMODYjYwG9SEIGvP02huBeGJ4Tzx+xM4PBzHf+5/ndhnp6qZhC9fd2CPHlmvDQO6ds1ad3QENzelrgfg5wc1a0LduiXd/Dz559w/+G4dz7JHp+Dt7Miczq9SwckZI/RP5XWbElX2Sebr2ONwcS14NYOH/oFKXWy634497nz16wP0G3yCjvIclYKehtiZUKWHknN1q5L1162y8qjLllXiVgAnT4IpGdIiITVKeeAOTmp2pGt5cHS3PkPGwREMFzBsT9Lz8vKiZs2a7Nixg6ZNmxIQEMCgQYNyPfZWeuQ29UxEYgzD2ArcC3gbhuEkIibABwgriQZq7l4kY1DvZqnpnZs9mSn/fMmBxgn88s7vN8aJrWXwYLWACrO8/DLUqAFbthRfY/NCBJLDSI0+wuqTy7jHOZ165kuUunyEq5fCCVzTjvZukG8QxsEVXLyh1efQeIySYrUCPz81cDlgADz1lIp916hRD2Q7BP8Ixz5RYZrr8Qd2OMO79aC8T4Zxfx5iEwEDXLyU8Xb2Alu+C5khLucy1mms5IKLiwsrVqygV69eeHp6MmTIEA7lFq+/xViTtVIRSM8w4qWAnqjwylbgKVTmynPAypJsqObu49kVz7ItZBuho0MB+HLnl5yPPc/0R6cD4BfiR7o5nZ71ehb5XqtOraTMpPcZ6ODIsIk7aGeFaJRVGAZs3aosHKg48EsvwWefqVkpRUEsEH0QLm2E2ONI7EliYwLwlkRiTTD4LIyr4IJv/da0rd2LQ62agLuPUvVz8shaHD3AOWObo7vyfG1tisD48ZCWBv37q27XqJH5HjhA/ZfVYklX+ifJlyH5EqRchlOrIXU/eDcEUwRE7IAaz4N7DXAtZ338OzsWE8QHqIeCa3nbz8+Gh4cHa9asoWfPnnh6etKvX798jx87diyLFi0iKSkJHx8fXnrpJXx9fYvUhgLJL+6iQjO0BA4CR4BjwEcZ2+sC+4Ag4A/AtaBrtW3btlAxI83dwcagjdLt526SlJYkIiJ/nf5LvtnzzbX972x4Rwb8NuDaeq9fe0n72e2vrS88slAuxV+y6Z4Ws1kmb/5MDF9D7v/mHgm7ElTEXhTArl0iFSuK7N1buPPT4kTOLxfZ/YLIsioqfr0QkRU1peMUL/nPD/VFTs8UubxFDpxZLyZTeqGbmpCgmhsRodYvXRL5+muRs2fV+okTIkOHisTGqvULF0SSkgp5M5Mpx2pucWKbMKeLxJ1W75edUZgYuVWDncW1aEOuyU58arz8fPBnOR9zXkRENp/ZLG1/aCunI09bdf6l+EsSeDVQREQiEyPF438eMnLtSKvvn5KWLH496suKRsjg3/4jiWmJtneiMCRmu88PP4js2ZP/8XGBIie/FtncU2SxszLcS7xk+6oHZMySRyQ9PlxiY0W+3DJLZmxbLMHBysgeOqSeF9u3q7HZtWtF/vkny/CKKGOduR4SItK1q8i6dWr98GFlIZYuVev+/mp95cqs9bp11diuzZjNIi+8oBqUC4U25BaLWuyYEhvs1GiKCxEh2ZSMu7M7kUmRPL/yeb7u9TWjOo3igdoP4P+K9eqY2XWry7uX58ArB64V8c2coONTxifXc68kXOHx3x+njUsQT933AIv+8xuGw02a6JxZYSA1FSZNgvvug7Yt1KSW7EvUATXgGBegji/TmOT6/8Wlel8cK3fj4P5Z/LzlC35oYCHhMsBrVjehfn01O3LVKnjhBRXpqVABzGY1NR7U2Oz69Sr/G6BlSyXx6pUx5b1tW1XDoVBcuQLbt6uLdLFtIDVfki+q6j+edW2Lp9s5WsZWc9OwiIWev/akpldNfu7/MwBHrxyleaXmxV4ppu/ivhy+fJigN4NwuW6w7thxP8b88jT/eMUy//H5Oaef28jFuEv8tOMvWpTpSv8uDXOvemNOU1kg0Qch5qiKEWca6+hwSL4KpVIgEpUy0CrjPAcXqNQdqj8G1ftwIjmF++fdz9y+c+nfuD/HA1Lo2tWgUjlXXnkFXF2VOJSra9brs2dV/LpDB7Xeowc0bari14cOwZkzWc2sUgXuuUctrVqpJBI3NyhV6sbFzU3do0gfW2KieqjlcpGTJ0/SpEkT26+ZEq4MeUEzPG9jcuu7lrHV3HKS05Mp5VwKB8OBh+s+nEP7OlNrurj5utfXnIw8ec2IRyZFUsG9An8F/oXT4/34MRLCD/xDmzr3FngtEcEsZpwcnAiOCua9TR8wpOZ7PHFvG05FnmL8/pd48PRB+neBNSeXMHTZCH5v9Ta9KgURdmUfoVEBtHEx42ygBhNLVQPXClCqOpRtpV67VoDPN8CK3XBgKVSrD+4+HI4MIjolmu6edWnobqJvw774lPEhOhqe7O+GgwXWroV6GfUgwsPh9OksJ7djRyUoNWaMWt+zB2rVUnWGQY3BHj4MBw9mLRs3Ks+8IAxDGXRnZ+tsprMzDGt3gpe9llDnp/G4ehRCGjYvMjNU3CoV3zXtCO2Ra3LFYoGEBOV9ORciaSCTned3MuD3Aax/Zj1tq7UtvgbawOqA1QxZPoRJPSby9sbR9JEGzO74GRUeHnDDsWnmNNYFrqN+ufo0q9SMC7EXaPV9Kz7tMpURnYdzIfYCjSd1p8w/07m4/RFS0hJYvfQPWvIvjUuvZ2tYGD02DORtoyZThv7A1IRyjDl7ilOP/ESjxp356/JpFhxdxMInFmIYBn+e+pMtZ7fw7SPfQmoqf22YzgGvJMbfPx4WLaJ95OeImxv+L+1TKSFubqSnw6OPqrrCy5apAvHtMny1YcPgr79U5MLRUQlSVa1qVUH4a6SkqIdBfLxSIbx+SUnJuZ6ebt11Y2Oh8ZKPeS5pFl1LH6brU5V5+ml44AH1sMmOTR65KQkSglU4xakYHw75IKL6LqL+R4ozKlcYj1wPdt6lnDsn8uabIkePqvWDB0VatVJZCiIiGzeqga08xqIKJCU9RUREYpJj5KklT8nJiJNFbnNhCYkMlhdG1ZGJ3Z2k+czmsvzkcjlw8YCIiJgtZuk0t5N8tfMrERFJM6WJw8cOMn7LeBERMZlNcu9n/xWXejuuTdzctk1k7RqzWM7+JrK60bWsEdn+pFiOfCaB/2yRC6cviVgssnH3RaHhKpk3T5075s/PpYJvI7lwQa2PWvaJlPGtfm2S6PBFY8TN11uurNknAvLL2O/kiSFREv7vBbX+4jZxdRWpyBUJ6PqCTBt9XkDkyiWziNksR4+qQcjbbrwvI/UlLdUimxdekmHDREqXVt+xSpVERo4U2bFDjYGK2DjYmZ4kEntSxGTbzE1bSUsTiYwUOXNGDSTv368Wf3+RkydV1k5UlDquKOisFY3VHDsm4uUlsnq1Wj99WqRfP/WlFFFfysmTlcEXUV9Ua43DG3+9Id3ndc9/+vdN5Hj4cfm5o6tMf9hbLsaGSbUp1WT4n8Ov7X966dPy88Gfr61vCzgow16JljNn1Pr+/SJffCESEyPqTTi/TGRNc2XA1zQTObdUxGLO9d7p6Sop5WrG7Pb169V/XeYDc9UqtZ75vv/xh1o/esQiEhUlK39LkgYNRIL2Rop89pl89EyQgMhnTx8TqVpVgn70k7VrRRK27lNpjZkXNplurTXPnj0yfbqIo6OygtlIThZZtkzkqadE3NxUv2vWFBk7VuTQISsMucWcdY8S6Gtw8Flp0qSZhIaKHD+eZbgPHhQJDlbPpqgokfPnVZaQv3/WMUeOiPTo0VcaNWomiYm2NU8bck2+HDigpCxiYmw/z9lZZcrlRZop7Zrhnntgrny4+UNJMxXRNSkKZrPItGly4dB2qT6lulSdXEVCz6wQiTkp/178Vy7Fnhcx596+c+dEypUT+eWXbBstFqU98tc9yoCvbiRydnGeBjy/ZqWlZXmemeuZ/+jXr2fnr79EHBxEBgzIOv8ahw+rpO4rV9T6L78oq3jhgogpWSRovkhShtufGi0SfaTkDP3evSLVq2flyh87JjJxYtbTLBdiY0Xmzxd59FERJyeRdetOyKlTItHReTTTbBKJOZ7Vp2LAYlEPlytXRAIDRVavPit16zaT/fuVIxMWptI183rbzGaR+HiVbz99+jLp3fvpa+cfOGD9/51OP9Tky/nzEBCgYpWZKWTW0Lo1fPop5CExQVJ6Eo8sfIS3O73NgMYDeLHNi8XS3iJx+TIW3wn8ud6RpAfgn+f+pvqe/uDdknu6r4Vjn8H5pdDzH3AuTXQ0LF2qZtPXrKmyOby8UEHQy5vgyEdKwtWzLnT6RSkAFmIGpINDznhqQeuZHDum3v9WrWDBglyOadkS5s/PWq9eHe7vCtWqQeIZ2DsM/q4Ks8+rfu97GRqvhDb9VIUch0KkoJhMKrgdHQ0vvghPPw3/+Y/KbezYMUvWsFkzteRDmTIwdKhaIiMhKEhlZwYFwddfq88j56CqA5jrqs+gEMkprVur66alQVycGg+Ij1froDJ8vL3V39at4fz5M/Tpk7+MrYODUt2FBBYvnsoPP8xm4MCB1KmjEnTcbKjbbCvakN8FpKerf4IBA9QgmYt10hnXcHCA995Tr00m2LAB+vTJ2m+2mHE0HEk3WznqVZIcOQItWxJTzp1nxlRlj+M5/hqyhWZV2kDXFcoQA3i3UKlqzip9Y/Zs4cMPDbp1g0YNLXi5RMDFQ3D8MzVl3L0mdJgDdZ8r3JTxIhAeDo89pozEqlVQYLKHCDh/ByMrqw+vdH3gM/COVIbXpz9M/x4+HQsn+6mH1OF5EDoCxk1Q17h4UVm12rXV+mefqSfcsGFqvWZN6NdPCY17eSld2rg4ta9cOTUKW0gqVICICGjcWD0jHByUUU9LA2dnC87O4ODgoORrbUREZeTExamHY0qK2u7kpDJ5qlRRDxVXVzh3Tj2LgoNtk7EdP348Y8aMwcPDHcNQ2mnli6YSUCDakN/hnD4NjzwCP/6otKBtNeLX8/338MYbsG8ftGqThoGqbfj3sL9vmrhVnqxZA337krJiKX2iphLqdIbzjSrjkXoMuBfKt1P/ySmR4FGLaLdHCV+/iEbld/FunYU8+f191A84BQdDwZLhmpWqDu1nQt0XrRaPKk5SUuDxx5Ux374dfHKf3wSJF+DKFvWgMQylWuiSLVVlyIdZ1QPcKsJL8+Dxq2q9fAc4vw5OnFTr/m/C/KVwvgP8+afatmIFtGmTZchfe00lpIOytPv3F1+nMzAM9UyYP195tOHhQpVSJ0k3O3ElqSGVKhmUKZPlpVssytHIXNLT1ZL5OjkZkpKymuzqqh4aZcqozJPcfpBERETQv39/li9fTtOM/uYnmnXo0CGCg4OZNm0aISEhxfuG5IM25Hc4Xl5Qp47yNIqD115Tk0natRMGLX0Wk8XE0oFLb60RT0lRv1t79cI0eRIDo39gT+ge/njqdzxiVkHpjJJbl/+GQ/8HUQcQgUcm7CY5vSoHP38OB0cH6vtcgdIdocZTSrDJoxZU7Vkoz684EFH6Wrt2wR9/ZKUYXiM9PkPkyhHO/ATHPoWqvaFUZWj1v/wvnr0WZc2n4KOnsm6afBE6d4ZBb6ltpkTw989p6T74oKjdswkPD6hTx8CU7ENCjBNJSQaBgVmTkjKNd24YhvK43dxUpKlMGTUPyZqUQVtlbHfv3o2/vz+1a9fGZDIRHh5O9+7d8fPzK3znrSG/AHpxL3qw8+YRHm7FWFYRB7vGr/5Onv52SpGuUWQmTRJp2lQkOVlMZpM8s+QJ+d93yK/7v8s65qq/yOaHRBYiUQtaiPnoJJFzS2XbyhPivyM8Z/aDiMiBMSKBc25+X67js89UOsJnn+Wy88p2kcWuIle2qfXkCJH4M8XfiMh9Iku81f1uIjkG/NKTVGGJbJjNKgnm9GmRoCClExMWpgYqo6JE4uLUwGV6euG/5mfPnpVmzZpJQkKCdO7cWRYuXFio822lMIOdd48YwR1MmjmNzWc2AxAcFcybq8fStlMy//d/1x145Yqqf5iQUbnvgw+gb98scQ0rEBHC4pT0fOjykWz532hiY4uhE7YiGRPZWreG++9H0tP579r/cip4Oe+Vc+TZCuUhPhh2Pg3r20H0QYIr/ESVFw7z/faxUPNJuvVrQtvOFZUmR6a3aU5TU+njM6rBp16FgOmQcDZjfyokhSo51hLs2pw5MG6cKkj8wQdAehz49YUzGQOaZe+BBq8rmVYAtwolUkgY5zJQvY+agQpKetaSh+tbUiRdgKTzSrY3AwcHFXdu0EDNaq1VS3nblSopaYHSpZUH7uRU9Jn6mTK206ZNY9WqVUXsTAmRn5Uv7kV75CXD/7b/TwxfQ06En5Bv93wr3hO95W3fC3LgwHUH7twp4uqaJW83darIa69lu9D/RJYvz/deE7ZOkIpfVpSwuDBJTlZpWjeVpCSRgQOVnmoGFotFJq1/TfBFPvj7A5FIf5F9I8Sy0ElGPTJdJo1aL5IaIxaLyMcfZ02CyhOLJWtyScRelW4Yukath+9S62EZ72HkPpG/2ohc3FAs3Tt0SFWJA5HPX54vaad+zmrTpu639peCxSKysYvI3w+U+K1yeKXmdJVCeZeg0w/vUkbfO5rGFRrjbWrCEz5NGDxy8DU9k9/+mMDjMVVwffl1pbJ3/rxyWwDefjvrImYz/PKLGhl9/HG1beVKePDBLGEOYEiLITgajlT1rIphqEwzgBkzVBxz+PAS7qybW9YIFkqI68fVj/NW/CqcWvVjQGp5ln0+lSfbLcFo8DIXXF7AwaEUuKgstY8+suIehpE1sFmuLTwRrooxAHjWhg6zwbtlxrEOquhw2TZq/fJmCN8OTd5VxRqsJCoKJn0SyaGtBzke1pPZs+GlegsxQtOh0XDVpoe2Wn29EqPJO1m/RkTg6n6o0KH472NOgcRzKlvIwQk9nFcA+Vn54l60R168rDy1UpLTladisYjce6+aZp85WcQ/zF/wRb57rJJ184YtlqwCwsePK7fwOxVr3ntknZrUkVlVIBvp6SL33y/y4otZ2wYOlGvT0jOPKTSnT6tZMJkVDjKCninpKTJ46WCpMt5dAn73EcsfFWREz+/E3S1ZEi8FZj/05nHkY5HlVbMmG8WeEknPW+fclBghP/wgUr68yHfPjZTUX90kKjxe7UyNvg3n2mfj/Ar16yQiY+JPWlzRPGeL+dr5Jw7vFok+qrzxuww9s/MuIiAyQBw+dpBP/D65tm3XLpFtm9NFpk2TTDGPLYdWSFqcGigKiQ6xfral2azELyIiZOWplYIvsqohSmhERImwtG6t5iKLSPrlSInYHShiMklqqsh992VFP5KSRNzdrz0TxGJRU5oLtFGZT6Rjx0QqVxbx87u2KzYlVp78pYs8+fKj4uacJCcnNxL5+0E5d+iwhIRY18USIz3jYWixiKxtqUIiuXBq0xIx/eogDauekm7dRE7uCxKJOnh7G+/spCeJnJicZbxPfKUGYFMyZnAmh+dv2FMiRRIzRGfS4tWg6vFJ6lInTqjZm3ch2pDfZWwI2iDHTqbIb79l2xgSooQrJk7McWyaKU0aT28s/Rf3t+raCakJEnQ1SExmk6Sb02XGvhmSHhUpkpoRO96xQ+SRR+Sa2tOcOerrFBys1v/5RwWk4+MlKkrpZ2zPSHzIdPYzPfakJJGrmw4opa5MevVSXngmycogxMSIjHwzQkaPHSCpC5Dkn11lRP8/5ey+3befAbRYRC77iVz6W62bUkXWNJWrR9fKsGEi1cqGytThH8mKRWG3XdMLRcRekaPZUmz2vKzK0WV2Lua4SPgO9dpiEVlaQZWsy+Tg+yKXNotIMZR6s2O0Ib8L8A/zl38v/ntt/ZlnRKpUEYk/FZp10OnTuRq15SeWy5YzW0REZM+FPfL00qclLC5MRESWHl8q1aZUu1Z2bdb+WYIvcjHOSi2Ls2dFfv45q/bixIkiLi5ZIZ3PPxdp3lwkLU2uhpyROU+ukbCBb4mIEk5ywCQH6v1HRFR0J/2rr0VmzhQRJdFx9KiIJIbKla0vSWWvi/Ll02MkdnkdlSpoJ1w9HyKn5/aXQV3+FBcXkfffV9ocdyyXt+QcnN3UTQ2WZhLyuxoszgVtyHOiDfkdhMVikXaz20nLWS3FnCHWlJAgcvqPQyobZfFiq6+1PnC91P+2/jV52d0XdsuLK1+8ZrgDIgNk3sF5EpdShOK1ydl+Vi+YJzKom8rwWIjIk4i0cxPZ0ltO/zlJPn7uH0nz/0skPUk+/1ykbFmVCywi0r5NsrRvekbMi5wkfQHyy/QycviU9X29lVy+LDJrlkiPHkoAEEQee+wWZPvcDlzZLpJw3qpDtSHPSUGGXBeWsDPC4sLYvieJVT834JdfMqbcp6SodIz331dJtLcT8UEQOAvO/Axp0WrqeL2XwJIKMcdU6bO4k1lT4g0HtoU8zZbT/fj47RMQfxq/9ZfxdE/g33KH2JRejgU1SuPaeQFU6Hhr+5YHly7B8uVKhGv7dpWm37Ch0pN66qmsGpiavCl0qbdiJCQkhMcee4xjx47ZdN7ixYv5/PPPMQyDatWqsWDBAipUqGD1+brU2x1KXGocvx37jZfbvEz1MtVJuqBKckWduEyVRl5KKOLLL291M7OwmFXR4MCZcGkDGE5Q4wloOAIqdr1xhobFBPGBEHsMYo5xf/Wj3N98HBwLAicPKnXtTi//fygnTdn0xHe4Hh2rSqOVACJKn8bPT+nJODsrvY9y5dQzMvN19vVSpSAsLMt479ihrtOkiZrU89RTaka8nZaQ1NiAyWRi1KhRnDhxggoVKjB27FimT5+Or69vid5XG3I7YM6BObz393u0Ln8fHWo358UX4ZmB6bjd+5ASUlm9+lY3UZESAcFzIfB7NROvVDVo8THUfxlKVc37PAcn8Gqilpr/ydpuSuLbvd8y6u/36V67O38O+hMvNy+ourvYrKKIkkrdulUZbz8/5VEDVKyobhMVlbeOByi9j9RU9bpFC/D1VcY7U1NKUzTeWv8Why4fKtZrtq7Smq97f2318WfOnOHJJ/OXsYWsUHViYiLly5cnLi6O+pmTLUoQbchvY8wWM44Ojoy+dzSc606/Ts3ZulV5em6lnVU4pXLlkm2ExQRpUVlV37MvKdetxxxWIZLKD0KbqeDTr9CSr8npybyz8V1m+s/kqaZPsaj5fTifmgQtP1UiUYVEBIKDcxruixfVvipVVP3I7t3V3/r1lSEXUaoGUVFKVjUqKmvJXPf2hieegEaNCt00zW1KQIBtMrazZs2iRYsWeHh40KBBA2bMmFHibdSG/DZlxckVfLjlQ3a9uAtvVy8e79iWUw9HUEv+hmO1oPl90KMOHB4HcVWhTEOIPaUU/hqNLJ5GnP8D9r6kdD5yw8kzqwK8awVoMEJ5315Fi20evHSQZ5Y/w8nIk4y5dwyTHpqE44E3ICms0J64CKxbBxMmKCE/UIa7e/espWHD3C9vGGpya+nSStNDc3OxxXMubmyVsU1PT2fWrFkcPHiQunXr8sYbb/DFF18wbty4Em2nNuS3KTW8alCnTDVk6zBo+Rp16z7KnCmBsGkIfOsGf5wGd0MNIJoS1UmBs+D8b1D7aXAtgpK9xQxHPoQTk6B8J6jzbE6D7VpBXb+Y5V3NFjNf7fqK8VvHU9GjIhuf3UjPej3VzvYzlaCVjXK5IrB5M4wfD3v2qEjUt99Cz57Ke9Zxa01+2CpjGxgYCEC9evUAGDhwIBMnTiz5huaX0lLci04/zJ8FhxfIlzu+vLZ+8cwlOfN1XVn23Vq1IT1RJGCzyHd5SMea00USQorWiJSrIpsfVimCe18r8crkmYREh0i3n7sJvshTS56Sq0lX1b33viaScK5Q1/TzyxKgqlFDZPbsolc419wcbof0w8LI2IaFhUmVKlUkPDxcRETGjRsno0ePtum+WjSrJIk9qQoUFKJOo7VsCN7A+djzjG7/Go7OnpStWoWpcUcZ/Iy7SlNp3RoaPqiW3HBwUsUQAE59Demx0GKC9Q2IPgzbH4fkMFXWrP5LRe1SgYgIC48uZMRfIxARfhnwC0NbDsUwDIg6COcWQ5WHwKOm1dfcvVt54Js3Q9WqqhrZSy+pQUmNxlYyZWx79uyJp6cn/fr1y/PYatWqMWHCBLp164azszO1atVi3rx5Jd/I/Kx8cS+3k0c+e7ZI3765VCO/HotFidovrSCy56Vib8cfx/+QczHK40xITRBTSpSq1H54fNZBBw+q2STffZf7RXJr8+4XRLY/ab1exdnFIr+VElleTSRij22dKCRRSVEy6I9Bgi/S5acucjb6rNqRfdJISqTV19u/X6kGgEilSkqlNympeNusuTncDh75rUIXlrCBo0eVomu+5Z4uLIe/71eTV9pNh8YZsq8WU1ZhgyIQnhjO8yufZ8quKQB4uHjg6OJNmncXfKd34sDWOHWfVq3gm2/gueesu7BhQMc50HmxyvAwp+TdXosJDr4Lu55Wkq29D9yUiTabz2ymxawWLDu5jM8f/By/5/yo7V0brmyD1fUgNCOl0opY/6FDqrB0+/awdy9MnKiqrr/9tsrx1mjuePKz8sW93E4eeXY2bsyj2EDI70pE33xdYNX/bZFtjxdaYvNKwpVrrw9cPCDp5nRVpivmnEhqqhw6JFKjQqLsNDor5b+ikJ4osrGzEiS6nuQIkb97qHj4vhE3JR4emRgpb617S/BFGk9vLP5h/jkPMKWKHHwvS0EvHw4dEnn8ceWBe3mJfPKJSGxsybRbc3PRHnlO0B75jSQnZ71OT4f//ldVQLuBWgPhwc035kJ71FBltQoRL98ftp+639Rl2YllIEKbcs3UQMX6B2BKHVizhlatIGhvFPd99JCqFFsUHN1U0YNybXJujzoIG9pBxA7o9DO0n16iVeJDYkJ4c92b1Py6Jl/v/Zr/tvsvB145QNtqbSH8H9j6KJiSVRtaTwTXcnle68gRePJJNWSwebNKKQwJUXHxor5dGo1dkp+VL+7ldvHI27cXef75rPUzZ1TR1mtc2SZybql1F4sNEPEflW/xgGskJ0vKxfMycu1IuXQlWKRaNaUKKCISukFMY5+VJV+eKThuXxRiT4sE/6ri4St8RCL3F/5aSZez9KRFlJZ0ZpGBDA5cPCCDlw4Wx48dxfkTZ3luxXNy9Mp1P3/C1omsbiQSH5zv7Y4cEXnySeWBlykj8tFHqtCu5s5De+Q5QWet5ERETZ+uXj1rW506Wftefx3G3f8dPh6HoPpj4FhAqsPlTRCyQJX2cnLPue/ECYiLQzp2ZM6/cxj61CeU6taD7375Re1/5X5olqReV3+YFe0fZuB/YG0zePTRYuluTmJPwV8tQdKh0v3QZQm4Vcr7+KRQEHNWJszRT9QkoCajAZCNnYhzuY+10Qs5dEj4v6bf41AjFK8H27MpeCPRe17hu7DzHLGU5u1ObzOq0yh8yvhkXDsMog+pwr7VekOVo3nOAj12DD75BP74Q03KGTdOxb/L5e20azR3F/lZ+eJebhePPC8SElRlm09801TM2loy47lHjoj8+JQq0Csi8sB9IsPryeHAZWL4GvLDt8+IrJslkhqlMks2PySytsW1WLvFIrJ2bQnVR0i6JLKhi4qH73lFxf0PfySyO9tPk+1P5tSL/vsBkY1dRUQp0kb92VcC5g2T114T6dRJZHDnZXJfwx0CSnrcu0yEVL53upQZ20oqfIrE/WrIxnX9JSY5RiQtVmRb/6zCAv8MFFlaMc9fMiaTqhU9cKCIYYh4eop8+KHSJtfc+WiPPCdojzwn//4LLVuCUy4995AQtmyqjEupUmDUITraSlXYzHjurNHQ4W+I6QEV70U+fx/jTF9aGrHsfnE3HcqUhTWNIMxTzZbs8ofSJnFwIikJ3N1LyBOP2A07noS0WLhvkZr5CYCAWLKOq/YIpMdfWw3xGMfy5SZ+ehtOnQKzeRUAXl4qPl3lnifo3RpmthYOmH/lo63jCUs4j2NUE+I2/kS71EG8+ZoDHe9zA8txiD0BpoxfIG2/VlP/s/2KSUyETZtg1SpYuxbCw8HTU6nzjh4N5YswWVWjsZXCyth++OGHzJ8/n+joaBISEnLsW7JkCb6+vhiGQatWrVi0aFHxNDY/K68eBNQAtgIngOPAqIztvkAYcChjebSga91qjzwyUqVjT5iQy06LWWRtq2v1Fa9cEalZU+Szz3I5Nsd52QoWx8eLXLokIiIX4y7K/T/dJ0eCVqgiuiKqOO2FP28Q11+7VqRq1aInqOTattMzRRY7i6ysJxJ12KrTgoJEnn02yxPu00d5w0uXqkpu2X8xhCeEy4DfBgi+SMc5HWV1wGpJSjbLggUiHTuqeLanp8iIESInT954r9BQke+/F3n0UVUbIzMDZfBgkUWLRKKji+Wd0NgZt4NHnjmz01Z2794tFy9eFA8PjxzbT58+La1bt5aojIGdKzkG5rIoKY/cBIwRkX8NwygNHDAMY1PGvmki8lXxPFJKHg8PFWdt3jyXnYYDtJmi8qpR3t9TT8EjjxRw0eefh9BQWL9euY+entd2XU2J4xLutHDxVhucS4NP/xsuUbUq3H8/NGhQuH7liikZ9r8OZ3+Bao/CfQvAJf+fF6Gh8Omn8NNPSof7nXfgvffy9oTXnF7Di6teJCYlhq96fsXb976NQ4YWyjPPqGX/fjWzcs4cmDEDHnoIXngBAgOV533ggLpWnTpqfKJvX+jaVd1fowHgwFtqPKU4Kdta/Sq0EmtlbAE6deqU6/Y5c+YwYsQIymb8zK9UKZ/xKRsp0JCLyCXgUsbreMMwTgLV8z/r9sTNDR5/PJcdImoSTZUe1zY5OsKUKVmHHD2qtKZv4IEHlIC1o5JWPRV5ikblG1G1dFUOvXoIRyskV++5BxYvtrEzuZCUpProkBQC/zwB0Qeh+QRo8VG+YlPh4fDFFzBrlqpm8+qr8OGH6gGTG/Gp8YzeMJq5B+fSqnIr/h76Ny0q5/bmqEk6v/wCkycrYz5rFgwZot7uTp3Uffv2VdrdWsBKcztiq4xtXpw+fRqAzp07Yzab8fX1pXfv3sXTyPzc9esXoDZwHiiDCq2EAEeAn4CyeZzzCuAP+NesWdPmnynFRUKCqp0YEXHdDotZZEtvkcAfcj3vx39/lKE/ThBQoYVG3zWSV396QmTrVhER6b2gt3zxzxciIpKUliTlJ5WXb/Z8Y1WbDh8W+eCD4plGfvasSKlSIv06bJSYH8tJ4i9esnbOatm1K6v25fVERan7e3iIODiolMyzZ/O/z45zO6TuN3XF8DXkvU3vSUp6ik3tTEsT2bZN1bLUaPLidgmtVKpUSRo1aiTHjx+3+fzrQyt9+vSRAQMGSFpampw5c0Z8fHwkOpfYYYkOdhqG4QksA94SkTjDMGYBnwKS8XcK8EIuD4rZwGxQNTsL8awpFvz81E/3hg3hweyaU6YEMBzByP23/J7QPVxyCmHSZBOPPurEqf3PUn/qPDj3Nhw4gLebNx7OHgCUci7Fw/Ue5pkWz1jVpnXrlJc6enQRp5KLsGjOOd579BfGP/4JIVFNeerb5RwMyorV1KunBnlbtVJ/T55UXnJMDAwaBB9/nH9RhDRzGr5+vkzaOYmaXjXZNnwbXWt1tbmpzs7QrVsh+qjR3AJslbHNzyP38fGhY8eOODs7U6dOHRo2bEhgYGCBoRqryM/KS5ZX7QxsAEbnsb82cKyg69zKwU6LRU3DT89tVr3FkmMELzwhXC7EqokuqaZUNYXeYhExmSQ5WeTSvvPF5lJGWq8JlYXZJBJ1UOTUdyL/DBLzsuoqrXAhIv8MEkmLF4tFJCREZOVKkU8/FXnqKZEGDdQApoolKdGwQ4cKvt3RK0el9fetBV/kxZUvSlxKHi6+RlNM3C4eua0yttm53iNft26dDBs2TEREIiIixMfHRyJzMQAl4pEbhmEAPwInRWRqtu1VRcXPAR4HbMvRuckYxnWDnCJwahrUGQpuFa9ttoiFHvN7UMa1DP88/w8uji5gNsOQp5FKlXk88BvCw2uwd2/hq3Ls2qXSHzt0sDKlzpQEV/ep6fQROyBiF5gy0gTdfTiT0JVpC7rwwntdadu5BRgGBqqaTa1akF11MzFRTbApVUp55vkhIny952ve3/w+ZVzL8OegP+nf+MbBWo3mTsYWGVuAsWPHsmjRIpKSkvDx8eGll17C19eXXr16sXHjRpo2bYqjoyOTJ0+mfDHl1BrK2OdzgGF0Af4BjgKZSccfAE8DrVGhlRDg1WyGPVfatWsn/pl1tm4iO3fCsmVqAO/a+xZ7Ata1hnu+gkZv5jh+Q9AGKrhXUDogmbz7LlSsyF/N3iU5xeDJJwvXFrMZmjVTpTb9/AoY4BML/PsOnP4OxAQY4N0cKna5toh7TVq1UiqOBw8W34BhfGo8w1cOZ/nJ5fRr1I85fedQyaP4Rtk1mvw4efIkTZoUrWSgvZJb3w3DOCAi7fI8KT93vbiXWxVamT5dpGzZjEFFU7bBudhTImaTpJvT5Z0N78iiI4tynpiaKpJR6SM3bJllmJ6epX1+6pQV51rMIntfUeGSXcNEQteqGaHX4eenwiRz51rfloIIiAyQJtObiMPHDjJl1xSxlMhUU40mb26H0MqtQqsf5sGIESpDsJQpGNY0gQt/qh1lGoGDIxaxsDdsL/9e+jfniaNGQceOEB9/wzX37VO5z2vWFHz/5GTo1UvphYAaVMxXJ0QssO9VCJoNTd+HTvOg+qO55oF/95261pAhBbfDGtacXkP7Oe2JSIpg09BNjL53tKrWo9Foblvumin6rq6AUw0odw+4VQbgRMQJanvXxt3ZnY1DN+LmdF0x4RdeULN0Spe+4XotWsDgwdCmzQ27bsDNTV0mU5wrXyxm2PcynPkZmo2Dlp/kGS+5cAH+/BPGjCl6AQWLWPhs+2dM8JtAm6ptWD5wObW8dcl4jcYuyM9dL+7lVoRWpn0aLH9/9ryY05JzbI9IjJDSn5eWEWtH3HhSWJhN97BYRBJz0X5audLGS5lNKoyyEJHDEwpUz3r/fZX/HRJiU3NvIDYlVvov7i/4IkOXD5WkNF0fTXNrua1DK2azUpGLjs79H7+IaNGsXKhe5jSdvFbgEPdfKJ81VlDBvQIz+8zkwTrXFTLevVslmi9cCE88YdU9Xn9dTTnfsCFLjOvqVXj2WRXy+P57Ky5iMcOe4UoSt8Un0GJ8voenpKgc9H79VGZKYTkVeYoBvw0gKCqIb3p/wxsd3tChFI1GBNLSIDVV/bNl/s18nZ2yZcHH55ZW974zDXlaNEQdgCoP8Z83e0NaCLh4XdtttphxdHDk2ZbP3nhuq1bKMj/44I378uDee9V0dgcHMJmUMS9fXlWvyXVa//VYTLB7mKoY3+p/0OyDAk/57TeIjIQ33rC6mTew8tRKhq4YipuTG5uHbeb+2vcX/mKa2x+LRYXp9IM6d0wm5YFdvaoGtrJn9Dk4KEPt7q4GpVxdVcw0Lg4uX1Yz6ypVUoYgN2nVkiY/d724l5sWWtk1TGSJl0SHx94QnYhPjZf639aXBYcX5NwRGamyVK4jOlrkgQdE/vyz4NvGxYn06KGm8luNOV1N4lmIyPGJVp1isYi0aSPSrFnhtMvNFrN8tOUjwRdpN7udnI85X/BJGvvlzBmlxVClilp+/bWERO+Lj5saWklKUvHJAwdE9u8XOXFC5Px5OevvL82aNFF2Ib/3KzVVaVvs3y/y77/ywahR4uPjc8OEIGvRWSuZtPoCHtzEQ4+U4emnc+6KT42nZeWW1CtXL2uj2ayEwJ944oZq8/PmwdatMHQoZGje5El4uHowW1030pIOO5+G87/DPZOh6XtWnbZ7t9JVHznSNufKIhZWB6zm3h/v5ZPtnzC89XD+ef4fanjVsP4iGvsgPV1NnujVC+rWhYkTlYJZzZrqy9ytGxw+fKtbeesQgehoCAiA48fVz9ty5aBJE7XUqKF+Vjs4gItL/v9oLi5Qu7ZSfvPwoG+rVuzLrAJWwDyd4uLOCq1EHVRlydyrIaWq8eKLUKFCzkOqlq7KsoHLcm50dIQ331TZKdk+MIsFZs5U4ZGLF+E//4E9e/LOEKldG7ZtU3K5BWJOg11Pw4Xl0GYqNH7b6m5+950q7vBsLpGh3DBZTPxx/A++2PEFR8OPUtu7NvP6z2NYq2H5x8NF1DTQmjXVDTW3P8HBMHcu/PwzXLmiDNLHH6sMLB8f9aX+6Sf4v/9TKVcjRqi82Hw0Qm4Lune/cdvAgapyelJS7hVZhg9XS2Sk0qQG9Z1OT1cDV2lpyghXr64MRT7ayVbJ2Lq7Q8OGdKpcWWlCWyyqIkuNGjnkrUuCO8eQi8CuIVCqKvTYgmGoUHd2/jz1Jx2rd6Rq6Wz6rJcuqbjWMzcKXf39txrEXLBAPZwfeUTFpOfOzb0Jjo5WGnGxwM5BEPontPkaGo+ytpdcvAhLl6p2FPTdSDWlMv/wfCbtnERwdDBNKzbl18d/ZXDzwTg5FPDRnzypHm5//61ifvffr0ZW+/a1Mo+yiCQmgr+/Glzq1Ek/SPIjLQ1WroTZs9Xn5eAAjz0Gr7wCvXtfk1gG1L6XXlK/PseNU2Lxv/8OX36pPHWHO/NHOhaLep/S09W6q6sysN7eBf6stVnG1stL/Sw3DHXPU6dKfkA0v7hLcS8lGiO3WESu/isSvlNERLZvz5kZFJcSJ6U/Ly0vrnwxa+MPP6hy7LmVrhGRfv1EKlYUScmYDPrhh2oW5bx5RWxr6JqMmPiXNp/60UdK+CooKO9jElITZOquqVJtSrVrcfAVJ1eI2WIu+AaxsSKjR4s4OYl4e4tMmiTy3nsiTZrINbWt5s1VzHXPnqzpqkXBbFZxyZ9+Enn1VZFWrVQpp8z7OTioQYG33hJZvjwXLeJbTECAyF9/iVy8eHPvm5YmMmOGSOXK6n2qWVPkk09ELlyw/hoHDqgCrKAK1h48aN156enqS/jXX+p7UMwx92KLkcfHi5w+reLXBw6oWLiVutHFImNrMqkc5AMHVFusoDAx8jvHkGcjIkL9748bl3N74NVACY0Nzdpw7pzIu++qN/s6QkLUNT74IGtberpI9+5K9/vo0SI0cEtvkeXVVAFkG0hNVf+zffrkvj8qKUo+8ftEyk8qL/giD8x7QDYFb7Juir3ZrJ5QlSurJ8VLL90oTxAYKDJ1qnoTMg1t5coiL76okuYvXVLnFLRcuCCyZo36gHr2VLXdMo22t7fIww+LjB+vauBt3qxq8z3wgIibW9ZxTZuKvPaaqgcXGppbj0qeEydEnn46p6RktWpKVtLXV2T16pIx7haLer8bNVL3vP9+9V7l8j22CrNZPUQrVFBf+hEjlFi9xaLe2y1bVD2+MWNU3xo1EnF2zuoziHToIPL773nIi9pOkQy5xSISE6MctP371cPp4kWb23b27Flp0KCB9OzZU374QdUrOHXqlLRq1SrX5Xpt8RyDnTbc++415OY0kUPjROKUm5qWJrJpk6ovKSI5PdHDh9UXsgDj9n//p77T587l3H7xorJdjRpZ/YDNSVyg8saP+Np86oIF6hNbv/7GfSfCT0jZiWUFX6Tvor6y6/wu6y/s75/llXXsqL78BREVJbJwoSquWaZMzn9qaxdHR5F77lEGed489Y+Xn4efkiKyc6fI55+L9O4tUrp01rXq1hV54w1l+NNse0DazKlTIkOGKAPu4aF+sWzZIjJtmip22qRJTuNetarIY4+pB9Lq1XlX+rCG/fuV4Qb1JVy1qvi84agoZcQdHNR76+6e8/NycxNp0ULkiSfUP8iPP6qfvjNnitSvr46pXVvk66+L1kcppCG3WFQfjh9X79OhQ0puupAPuOKWsbWWu9eQR+wVWeQkcmFlrruHLBsib/71plqZMUN5HvmUwklOVocMGJD7/i1b1Hf96acL8T/k/7Zqa5KVnlpIiDIQ334rHWtfloaVo8X848/Kqv/2m8iyZZK4Yok0n1RLKv7PWw5uX6JyJq1pWHi4yMsvK6NTubIypoUJlaSmivz9t1Ins2aZOVMZgMyi1YUlPV09hKZOVYYy02MvW1YZ1KVLC/m0zYOAAJFnnlEfvru7yNixeYuqxcWpPuZm3F1c1K+O6dNv9BTyIiRE3RtUvG/mzJJ7YB08KDJ8uAplzZypPttz5/L/bphMIitWiHTuLNcqaL/3XqF/LdlkyM1m9TP86FFlwI8cUZ9LEcN+2YsvR0dHS7t27WTlytxtTHbeffddqV69uhiGIdWrV5cJuVZ7z5u715CLiCSHi5jTJD5e5Msvs6bGm03pMmZqb/nsx+fUBpNJPbXzYf589c5s2pT3MZ99po6ZNcuGNqYniizxVnnj1pCQIFKvngjIPtoJiHzLyBs82xf7IcYEZEO9bNs9PUUaN1ahixdeUN7g3LkiGzaokMC336owhpOTionHxNjQkduUhAQVQx82TBlzEHF1VUZ+7lyRPKqWF0hAgMjQoVkG/N1381XFzJP4eOUFjBmjqnxkflatWqlQ0v79NxqfmBhlEF1d1YPqgw/UOMbtzO7dqpKJg4P6fg0dal0Fk2xYZchTU9Vneviweu+OHVOyord5jnxBFMaQF6hHXpzcDD3yjRtV6uzWrRkZS+npqrpxixZWVzju1Enlg588mfeAtsUCffrAli0qr9sa8SyC5ipBrIe2QyUryqS99RZ88w2sX8+wn7qzYq0zYfsvUaZUuuqXycSvwcsZdmAcH9Ydzme1nlezzC5cuHG5cuXGnNaHHoJvv1V5s3caJhPs2KFUxf78E86dUx9m585qKV1apRhdv3h6Zr1OTISvvlJpS66uKtVt7Fg1g684CAiAVatg9Wolmm+xqAyqvn1VhtDZs+Drq2YaDhsGn32mMi3shTNn4OuvVbpjYiL06AE9e6r/x9at830fc9UjT09XSqTx8WpGZeZUeQ8P9b55ed0Rs1bvTj3yM/NFtj8pkpblpYQcjpH08R/Lv+f2yqFLh1Rg28qfWf7+ykn6xor6yRERIj4+InXqqGhGvlgsImtbiaxtaZ3HsH27+ik+cqRcuaJ+jY8cmfOQkxEnxeN/HtL1p66qHF1+ZM4+275dxbY3brR7z8VqLBYVLpgw4caMmIIWNzf1i6Wkq0VHRKifgk89pX5NZd7/gQdUxoM9c/WqGteoWzfne1utmhq5HzdOZNkyNQM14zt54sQJ9es5Jkbk/PmsuHdm9snp0+ozSUy8477Hd6dHHjgLQhbDQ9uynsbr10OfPjwytQ3HLVc4M+pMwXnTGbzwAixZAmFh1qUu79qlUqwfewyWL8/HIYjYCZu6QIcfoP4r+V80MVFpvojAkSN8Ns2D8eNVOmpmgeSk9CQ6zu3I5YTLHHr1ENXLVLeqfxqyBJESE/Nf0tPVB1ulys1tX2qqmlnm4qK+XHeAl3mNqCg4dEgtBw+q5dQpNbsa1D9d69acnDCBJmXKqM/KMNQvpdKlVX62u/udm+/O3eqRZ2Pr1mxZc8HBEpUUJXtD91p9fmSkcsBefdW2+06ZohyMKVPyOWjHYJElXiLpVgzwjRqlLrh1q6SlKcfl4YdzHvLSypcEX2R9YC4pLBqNPZGUJLJvn5rX8dprIh07yoktW1Saamxs8cxVsCPuvsHO1Ogcq7N7LZXqXvGSlFS4n1qTJ6t35MgR286zWFSGi5OTyo67gaRLIoudRfzfKvhi2UIqFotKsgGVtZbJr4d/FXyRD/7+IO/raDR2zG2tR17C3F2iWSKwsRPsfVmtWyy87PAj54aOY+npBfSY34OrSVetvpzFArNmQdeuVkrPZsMwlLRFjRpq/HDIEFi7Nms2MEFzlEBWg//mf6HERHj+eS7V6MAXFabQsKGSwmjZUskDgNIPf23Na3St2ZWPH/jYtoZqNJo7Ejs25GZoMAKq91WrhgP89ReOX08BwMXRhbKlbqxxmRfr16tB9hEjCtccb2/YtEklF2zYoEKr1arBGyPTST3xPVKlF5RpkOf5JhOsHryQ/sFTqBG6mw98XahWDebPV1kxjo4qLv6fP/5DKedSLH5ysdVxf41GYzshISE0b9680Of369evSOfbgv1aAgcnaJRRVSEtjZEjIOSiC2vWODK01VCGthpq0+VmzFBjWo8/Xvgm1aunRNW+/VY9GBYuhKuHVuJ630Vemvw9VbYoba7s4xjBwSo76+cfUrl09RUqu8fxzhsGL7wADRvmvP6odaM4Fn6Mdc+s04ObGs1tzPLly/EsYcXD7NinIbekw8X1ULUXOLrA77/TYP4x3IaP5K/AIzza4FGbypWdOQPr1sH48SpRoKi4uKg04H79wLR+OvFXaxNqeZSfv4D//U+l0fbrB//8o/LQHRyER9x28lLlJfQ5NQVn7xuvufDIQuYenMv7Xd6nd/3eRW+kRmNHFJeKbSZ+frbd3yoZ2wwSEhKYOnUqs2fPZuDAgbbdqJDYZ2jl0kbY3g8ub1TrrVvz1psWGr/8F48tfox/L/1r0+VmzVLZTK8UkBVoMzHHcIraRul7Xmf9BkdCQ2HaNBUm+fhjNd/j00/h3HMTWJPUgwG/DcbZ+0Yd3IDIAF5d8ypdanbhkwc+KeZGajSa/AgICODJJ59k3rx5lClThtatW+e6xMTEADB+/HjGjBmDu7v7zWtkfiOhxb0UW9aKOU1JwWaoB4aEqAylVFOqrDy10jq1vwySkkTKlVPzMIqdfa+LLHYVSb5RdvWaFMS2bSot5frZPpntS0uSFjNbSIUvK8iFWBvkSTUaO+Z2yFopjIztwYMHpW/fvtfOz9RqsYXCZK3YZ2jFwRmq9wHA8utC7n1nEI885sSPP7rQr1E/my71229qjkJhBznzJC0Wzs6H2k+DW4UbdlesiMpSeeGFrFJcufDR1o84Gn6Udc+sw6eMTzE3UqPR5IeXlxc1a9Zkx44dNG3alICAAAYNGpTrsX5+fuzevRt/f39q166NyWQiPDyc7t2742drLMdW8rPyxb0Ui0d+YaXIyWnKG4+KkjQXD5n/yAJ5eNZQWXmqYGWy7FgsIm3bFr6Icb6c+lbJ1UbmIwn75pvXJv7kRmRipLj/z12GLh9azI3TaG5vbhePvCgytjfTI7e/GPnFv9S0fMMJypbFOfAEj8y8h4tykEvxl2y61L59cOCAGjAp1lnQIhA4A8p3gPJ5zKrdvl2lt4wcmftIDjBz/0yS0pMY23lsMTZOo9HYgoeHB2vWrGHatGmsWrXqVjcnV+xTayUtBly8EVGhkUceAS8vwSxmm3Krhw1TwnhhYUrGodi4/Dds6Qn3zoc6uaRBXr4MXbpc01LJrdBncnoyNb+uScfqHVkzZE0xNk6juf3JVf3wLqEwWiv255EDuHjD/Pn4P/oRQ16MYvnKNAzDsMmIR0SomrPDhhWzEQc4PQNcK0DN/9y478QJpZN76RL88kue1ZrnHZpHZFKk9sY1Gk2B2I8hF4FNXSFgulq/epW28X70+WYMX8S2wGwx23S5n35SAnj/LWDWvM0knoewVVDvZXB0y7lv61a47z5VGX7bNuWV54LZYuar3V/RsXpHuta0Qrdco9Hc1dhP1oopAUpVBecyav3tt3F46y3ePLOJ4KgOODo4Wn0piwVmz1YKoU2bFnM7A79Xfxu8lnP7/Pnw0kvQoIESYqldO89LLD+5nDPRZ5jcc7JNE5s0Gs3dif0YcufS0GWJen3hAkdjarBkicGbbz7Mw/Vsu9SWLWo252efFXMbzSkQPEfpv3jUVNtE4JNPVKWXBx+EZcuUMEseiAiTdk6iQbkG9G/Uv5gbqNFo7kTsI7RiSYeUcPX67FmoXZstX63ji21TSDTF2Xy52bOhfPmi6arkyvk/IDUSGo5U62lpao6wry8895zSAcjHiANsDdnKgUsHePe+d236laHRaO5e7MOQX1wPK6pB5F4oWxa++IJKLwRj7vEOVyXQpktduQIrVii76uZW8PE2EfwjlG4AlXuoop+9e6uQyiefKJ1bK4Rcvtz5JZU9Ktss+qXRaO5e7MOQezeHZh9CuTbKox07lqfvH8mpEadoW62tTZf65RclGfvyy1aeYDIpScMffwR/f0hOzv24xHMQvg3qDFOFfu+7TxX/nT9fqXFZEes+fPkwG4I3MKrjKNycivspo9FobKGwMraLFy+mRYsWtGzZkt69exMZGVkCrcuJfcTIPetAy49VaMLRkYkHHuLoMQd+/bWRTZcRgTlzoFs3aNzYihPMZuW6L1qUtc3BQenLtmqllpYt1d+YBWp/fAt4qJOqu7hxY56TfXJj8q7JeLp48lq71wo+WKPR3HaYTCZGjRrFiRMnqFChAmPHjmX69On4+vqW6H0LNOSGYdQA5gOVAQFmi8g3hmGUA34HagMhwEARiS65pgKTJiGJCcx67BPKlx6Eg8MbNp3u5wdBQSpkXSAWC7z6qjLin3+udDAPH1YTeA4fhr17VSJ6JlMcQMrAy0OgUiWVamjDhIZzMef47dhvjOo4yqaCGBrN3UD3ed1v2Daw2UD+2/6/JKUn8ejCG3Vsh7cezvDWw4lMiuSpJTl1bP2G+9l0f2tlbDOnzCcmJlK+fHni4uKoX7++TfcqDNZ45CZgjIj8axhGaeCAYRibgOHAZhGZaBjG/wH/B7xXck0FNmwg/uwpOh+fRJ/Hy9l8+uzZKsT+5JMFHCgCo0apcMr48fD++2p7gwY5hY1jY+HoUTi2Gsp8CVvKQfemKkm9cmWb2jZ191QMw+CtTm/ZdJ5GoylZAgICGDx4MPPmzcPNzY3WrVvnepyfnx/e3t7MmjWLFi1a4OHhQYMGDZgxY0bJNzI/IZbcFmAl0BMIAKpmbKsKBBR0bnGIZsXHF+688HARFxdVoD5fLBaRd99VYlZjxlinpuX/lshiF5HUqEK1LVMc67kVzxXqfI3mTuN2Ec2yVcY2LS1NHnzwQQkKChKLxSIjRoyQTz/91Kb7lrholmEYtYF7gL1AZRHJVKm6jAq95HbOK4Zh+BuG4R8REVGIRw1w+jS0bcvZHWto3yPU+oHKbMyfr7IBCzz3k09g8mR4/XX1t6BBSosJzi2G6o+BS+FCIpniWO/c906hztdoNCVDdhlbUN55foUlDh06BEC9evUwDIOBAweya9euEm+n1YOdhmF4AsuAt0QkLvuMQxERwzByVd8SkdnAbFCiWYVqZcYD4P/OzuXCozt5sEkYYH1NNhEVVuncGZo1y+fAL79UAfThw2H6dOskES9vgpQrUPtZq9uTneT0ZL7d9y19GvSheaWbU6hVo9FYh4uLCytWrKBXr154enoyZMiQa8Y6N6pXr86JEyeIiIigYsWKbNq06aaIf1llyA3DcEYZ8YUisjxj8xXDMKqKyCXDMKoC4SXVSDp3hgMHmBQTwrNXjtK3kW2FNbdvV079hx/mc9D06fDeezB4MMydq7JTrOHsAuWJV8ulaKAVaHEsjeb2JlPGtmfPnnh6etKvX97Fa6pVq8aECRPo1q0bzs7O1KpVi3nz5pV4GwuUsTWU6/0LECUib2XbPhm4KlmDneVEJF9rVFQZ2x07oGNHcHbO56Aff4Ry5dR0eC8vQFWu/+svuHgRSpXK45yXXoIBA2DJkgJukI30eFheWeWOd/je1u5gtphpOL0hFd0rsvvF3VpXRaPJQMvYFr+MbWdgKPCgYRiHMpZHgYlAT8MwAoGHMtZLhMikSAYueJGu/c6Q7wDw2bPKID/xhJqD37UrVz+YwrKlFp59RnI34osWqcB5795K3NxaIw5wYQWYk3PXHLeCZSeXcSb6DGM7j9VGXKPRFJoCQysisgPIy8r0KN7m5I7/RX/WXVjCtzNH82S3fA48fVr9nToVIiNhwwZ+/eICqTjwyoKucNUHevWChx+GatVg+XIlSN69u3rt6mpbw0J+BY86UOE+m/skIny580salm+oxbE0Gk2RsIuZnb3r9+bSmEt4unjmf2BQkPo7eDBUrYp89j9mNzbRyRJJi3vrqJmWv/2mjmneHAICoEMHWLUqj5hLPiRdhMubofm4QtWJyxTHmv3YbC2OpdFoioRdaK2EhsIvczyJLmjeaGCgqrhTpQoAO3fCydNOvPJBBZV/ePEiHDyoKtZXrAh9+qhp/54FPCBy49wiQAqVrSIZUrVaHEuj0RQHduGRb9igahT36qVmZuZJUBDUr3/NQ549G8qUgYEDM/Y7OEDr1mp5r4iTUM/+qoorl2lo9SmXEy7zy6Ff+PHgjwRGBTKxx0QtjqXRaIqMXRjyF19UQlcFShYEBioRKyAqSiWgvPhinmUxC0/0EYg5Am2/K/BQk8XEhqANzD04l9UBqzGLma41uzKu2zieafFMMTdMo9HcjdhFaAWUzEm+mEwqayXD2i9YoAQICzMLtEBCFoDhBLUG5XnImegzjNsyjlpf1+KxxY+x68IuRt87mlMjTrH9+e0MazVMx8Y1mtuYwsrYfvjhh9SoUQPPXEK2S5YsoWnTpjRr1owhQ4YURzMBO/HIreL8eUhPhwYNrsnVtm+voijFisUMIYugam9wq5hjV6oplRWnVjD337lsPrsZB8OB3vV7890j3/FYw8dwcbRtIpNGo7E/+vbty8iRI2lwnfcZGBjIF198wc6dOylbtizh4cU3h/LOMeSZGSv167NnDxw7pox5sRPuB8lh0GZKjs0HLx3k2RXPciLiBLW8avFJ908Y3no4NbxqlEAjNJq7jL+737it5kBo+F8wJYFfLjOr6w5XS0ok7MgpY8tDfjbd3loZW4BOnTrlun3OnDmMGDGCshkDfZUqVbKpDflx5xjywIySbw0aMPsDlYgyeHAJ3Ofsr+BcBqqrabomi4lJOybhu82Xiu4VWTFoBf0a9cPBsJuolUajyQdbZWzz4nTGPJfOnTtjNpvx9fWld+/exdLGO8eQBwWBuzsxblX4/Xc1z6cwWYX5YkqCC8uUJ+BUiqCoIIatGMbu0N0MbDaQWX1mUa6U7TrpGo2mAPLzoJ3c89/vVsFmDzyTiIgI+vfvz/Lly2natClAvqJZ+WEymQgMDMTPz4/Q0FC6devG0aNH8zX+1nLnGPLAQKhfn4WLDJKT4ZVXSuAeoSvBlIDUfoY5B2YzesNonBycWPjEQp5u/rSeZq/R3GFkl7Ft2rQpAQEBDBqUe5JDQR65j48PHTt2xNnZmTp16tCwYUMCAwMLDNVYw51jyIOCkGbNmT0b2rRRS7ETsgCzWzUGbJnCmsC/6FGnBz/3/1nHwTWaOxRbZWzzY8CAASxevJjnn3+eyMhITp8+Td26dYulnXdGINdshjNnmBz1AkeOwH//WwL3SL6C5eJ6podH8ffZLXzT+xs2Dt2ojbhGc4eTKWM7bdo0Vq1aVeDxY8eOxcfHh6SkJHx8fK4VXu7Vqxfly5enadOmPPDAA0yePJny5csXSxsLlLEtTooqY5snZ8/yZ923ecJYwcCBBosXF0r+JE9iU2JZvfphnk3fx3+SmvBJ/2U0qXh3SmxqNDcDLWNrm4ztHRFaObj+Cs+wkPaN4/n55zLFasQjkyLpMKcDv5c+yyXPyix8/pDOB9doNLcVdm/IL16Evh80pzxXWbnIhVKlyhTr9UdvGI178nnaVwRajAVtxDUazW2GXcfIk5Kgf3+ISXRmtdtAqrTKtf5zodkUvIlfj/zK9CadwHCA2k8X6/U1Go2mOLBbj9xigeeegwMHYGW7SbRKTS7WwHhSehKvrX2NhuXqc79cgMoPQamqxXZ9jUajKS7s1iOfMAGWLoXJk6Fv/GIrpBFt42O/jzkTfYZF3d/GSDoPtYtP4Eaj0WiKE7s05AsWwGefqfKco0ep1MOC5RGt59DlQ0zZPYUXWr9AW0sYGI5QvW+xXV+j0WiKE7sz5Dt3Ko3x7t1hxgwwQi9AWlqxeeRmi5mXV79MeffyTH54sprNWbEruOqp9xrN3URJyNiWFHZlyENC4PHHoVYtWLYMXFzIIZZVHHy37zv8L/rzTe9vKGeKhtjj4KOLI2s0Guvo27cv+/btu6n3tBtDHhcHjz2m6kesWQPlMh3kbPK1ReVczDnGbRnHI/UfYVCzQcobB/DpV+RrazSaItC9O8ybp16np6v1BQvUelKSWv/9d7UeG6vWly9X65GRan31arV++bLNtz9z5gz33HMP+/fvL/DYTp06UbXqzU2MsIusFZNJSdIGBKj6nQ2zl8kMDIRSpaCIb5yIMOKvEQjCzD4zlQBW2Crwag6exaOHoNFo7I/ikrEtSezCkL/3nip2P3s2PPjgdTszCy47FO3HxR8n/mBt4FqmPjyV2t61IfUqRPwDTd8v0nU1Gk0x4OeX9drZOee6u3vOdS+vnOsVKuRcr1LF6tsWp4xtSWIXhrx/fyhTJo/6m0FB0Lhxka4fnRzNm+vepG3VtrzR8Q21MWwtiEXHxzWau5jilLEtSezCkHfrppYbMJshOBj6Fi01cOymsUQmRbLumXU4OWS8JWEroVQ1KNe2SNfWaDT2S3HK2JYkdjPYmSuhoUVOPdwWso25B+cy+t7R3FP1HrXRnAKXNqjccV2yTaO5qykuGduSxC488l0XdhEaF8oTTZ7I8pihyKmHKaYUXlnzCnW86zDh/glZOy5vAVOiDqtoNHcxtWvX5tixYwB4e3tblbEC8OWXX/Lll1+WZNNuwC7czTn/zmHQ0kHU+aYOE3dM5GrSVbWjiKmHn//zOaevnub7x77Hw8Uja0fYSnDyhMrXj6xqNBrN7YddGPK5feeycvBKGpZvyPub36fGtBq8svoVjgfvVqmH1arZdD2zxYxfiB8Td0zk2ZbP8nC9h7N2igVCV0HV3uDoWsw90Wg0muLHLkIrjg6O9GvUj36N+nH0ylG+3fstvx75lTmeKfQY7sGowLX0adgHhzzi2UnpSewL28fO8zvZcWEHuy7sIi41joruFZn68NScB1/1h5TLOqyi0WjsBrsw5NlpUbkFc/rNYeJDE5nzbBNmNEmg32/9qFe2Hm90eIPn73meVFMqOy/sZMf5Hew4v4MDlw5gspgAaF6pOUOaD6FLzS70rNeTih4Vc94gbKUSyar26C3onUaj0diO3RnyTMq7evN/a2MZU38kK4Z05Ju93/DWhrd47+/3SDWnAuDi6EKH6h1459536FKzC/fWuJdypQoQv9IiWRqNxs6wW0OemXro3KAxA5sNZGCzgfhf9OfXw79SrXQ1utTsQttqbXFzcrP+mvHBSiSrzbSSa7dGo9EUM/ZryHPJWGlXrR3tquVZaLpgwjJyRLVIlkZz1xMSEsJjjz12LQXRVvr168eZM2cKfb4t2EXWCulxEL4j57bMHPLirAwUulKLZGk0miKzfPny20uP3DCMnwzDCDcM41i2bb6GYYQZhnEoYynZkcF9r8O2vpAWm7UtKAjc3KB69eK5R6ZIls5W0WhuO26xiq1NMrYJCQlMnTqVcePG2X6jQmJNaGUeMB2Yf932aSLyVbG3KDeajIFziyDgW2gxXm0LCoJ69YqsengNLZKl0WhywVYZ2/HjxzNmzBjc3d1vWhsLNOQist0wjNo3oS15U64NVO8Hp6ZCozfBxUuFVnIIkxcRLZKl0dy23CIVW5tlbA8dOkRwcDDTpk0jJCTE+hsVkaK4syMNwziSEXopm9dBhmG8YhiGv2EY/hEREYW/W4sJkB6jvHKLRakeFld8/JpIVj8tkqXRaK6RXcYWlHfeunXrXJeYmBh2796Nv78/tWvXpkuXLpw+fZru3buXeDsLm7UyC/gUkIy/U4AXcjtQRGYDswHatWsnhbxfTq/c43FITS22Op1ZIlk6W0Wj0WRhq4zt66+/zuuvvw5kZb34Zf85UEIUyv0UkSsiYhYRCzAH6FC8zcqDTK/82BS1XlweuRbJ0mg0eWCrjO2toFAeuWEYVUXkUsbq40DJJ0pCllceugRKUTweuRbJ0mg0uVBYGdvczi9pCjTkhmEsBroDFQzDCAUmAN0Nw2iNCq2EAK+WXBOvo8UENXGnj1PxpB5qkSyNRmPnWJO18nQum38sgbZYR7k2EFYFekeAKV5lsBQFLZKl0WjsHPtM0djgDqXMcPq7ol9Li2RpNBo7x/4MucUCOy9CbD2VwZJ9tqetZIpk6bCKRqOxY+zPkIeFQUoKOA2EtOiieeXXRLK0IddoNPaL/RnyTLGsuj1UlfuieOWhK8G7BXjWKb72aTQazU3G/gx5pnxtgwYqg6WwXnmmSFZ1PQlIo9HcSEhICM2bN7f5vMWLF9OiRQtatmxJ7969iYyMLIHW5cT+DHlgILi6go+P0kUprFceukqLZGk0mmLFZDIxatQotm7dypEjR2jZsiXTp08v8fvanyG/XvXQVq88PR4OjoX9r0LpBlokS6OxA7rP6868Q/MASDen031edxYcUTq2SelJdJ/Xnd+PKR3b2JRYus/rzvKTSsc2MimS7vO6szpA6dheTrBdx9ZaGVsRQURITExERIiLi6NatWo2389W7K9CUFBQzqn52b3yRm+Cc5nczxOBkIVwaCwkX4K6z0OrL7RIlkajyRdbZWxnzZpFixYt8PDwoEGDBsyYMaPkG5n5BLkZS9u2baVImM0ibm4iY8bk3H7VX2QhIkc/y/28qwdENtynjlnXXiRiT9HaodFoSpQTJ07c6ibI2bNnpVKlStKoUSM5fvy4VeekpaXJgw8+KEFBQWKxWGTEiBHy6aef2nTf3PoO+Es+ttW+PPKLF1Xq4fViWeXaQrXH4NQUaPRGlleeehUOfwhBs8G1AnT8EeoO1164RqOxiuwytk2bNiUgIIBBgwbleqyfnx+BGVl19erVA2DgwIFMnDixxNtpX4Y8M/UwN7GsFhNgQ3sI+A6a/h8E/QBHxql6n43ehBa+4OJ9M1ur0WjsHFtlbKtXr86JEyeIiIigYsWKbNq0iSZNmpR4O+3LkGemHuYmX1u+XZZXfv4PiDkMlR+Att+Ct+0pRBqNRgNZMrY9e/bE09OTfv3yTlmuVq0aEyZMoFu3bjg7O1OrVi3mZRYbLUHsy5Bnph7WqJH7/hYTYEMHpS3eZQnUeAoM4+a2UaPR3BEUVsb2tdde47XXXivJpt2AfRnyoCCoWzfvgsvl28GjR8GzNjh53NSmaTQaza3Cvgx5YGDBxSS8m92ctmg0Gs1tgv2kbxR3wWWNRqO5Q7AfQ37xIiQna0Ou0Wg012E/hjy7WJZGo9FormE/hjwzh1x75BqNRpMD+zHkQUHg4pJ36qFGo9EUI4WVsf3www+pUaMGnp6eN+xbsmQJTZs2pVmzZgwZMqQ4mgnYU9ZKZuqho+OtbolGo9HkSd++fRk5ciQNrgsDBwYG8sUXX7Bz507Kli1LeHh4sd3Tfjxya1IPNRrNncnf3eHMPPXakq7WzyoZW0xJav2ckrElLVatX1AytqREqvVQJWNLcsnJ2AJ06tSJqlWr3rB9zpw5jBgxgrJlywJQqVIlm9uRF/bhkYsoj/yhh251SzQazV2GrTK2eXH69GkAOnfujNlsxtfXl969exdLG+3DkGemHmqPXKO5O3nIL+u1g3POdSf3nOsuXjnX3SrkXC9VxerbRkRE0L9/f5YvX07Tpk0B8hXNyg+TyURgYCB+fn6EhobSrVs3jh49mq/xtxb7MOT5iWVpNBpNCWGrjG1+RtnHx4eOHTvi7OxMnTp1aNiwIYGBgbRv377I7bQPQ56ffK1Go9GUELbK2ObHgAEDWLx4Mc8//zyRkZGcPn2aunXrFks77WOwU6ceajSaW0SmjO20adNYtWpVgcePHTsWHx8fkpKS8PHxwdfXF4BevXpRvnx5mjZtygMPPMDkyZMpX758sbTRUFWEbg7t2rUTf39/20+cOxf27FF/NRrNHc/JkydvSkGG25Hc+m4YxgERaZfXOfbhkb/0kjbiGo1Gkwf2Ycg1Go1GkyfakGs0mtuSmxn2vV0obJ+1IddoNLcdbm5uXL169a4y5iLC1atXcXNzs/lc+0g/1Gg0dxU+Pj6EhoYSERFxq5tyU3Fzc8PHx8fm87Qh12g0tx2Zk2Y01qFDKxqNRmPnaEOu0Wg0do425BqNRmPn3NSZnYZhRADnCnl6BSCyGJtzO3Cn9elO6w/ceX260/oDd16fcutPLRGpmNcJN9WQFwXDMPzzm6Jqj9xpfbrT+gN3Xp/utP7AndenwvRHh1Y0Go3GztGGXKPRaOwcezLks291A0qAO61Pd1p/4M7r053WH7jz+mRzf+wmRq7RaDSa3LEnj1yj0Wg0uaANuUaj0dg5dmHIDcPobRhGgGEYQYZh/N+tbk9RMQwjxDCMo4ZhHDIMoxAlk249hmH8ZBhGuGEYx7JtK2cYxibDMAIz/pa9lW20hTz642sYRljG53TIMIxHb2UbbcUwjBqGYWw1DOOEYRjHDcMYlbHdLj+nfPpjt5+TYRhuhmHsMwzjcEafPs7YXscwjL0ZNu93wzBc8r3O7R4jNwzDETgN9ARCgf3A0yJy4pY2rAgYhhECtBMRu53EYBhGNyABmC8izTO2fQlEicjEjAduWRF571a201ry6I8vkCAiX93KthUWwzCqAlVF5F/DMEoDB4ABwHDs8HPKpz8DsdPPyTAMA/AQkQTDMJyBHcAoYDSwXER+Mwzje+CwiMzK6zr24JF3AIJE5IyIpAG/Af1vcZvuekRkOxB13eb+wC8Zr39B/ZPZBXn0x64RkUsi8m/G63jgJFAdO/2c8umP3SKKhIxV54xFgAeBpRnbC/yM7MGQVwcuZFsPxc4/PNQHtdEwjAOGYbxyqxtTjFQWkUsZry8DlW9lY4qJkYZhHMkIvdhFCCI3DMOoDdwD7OUO+Jyu6w/Y8edkGIajYRiHgHBgExAMxIiIKeOQAm2ePRjyO5EuItIGeAQYkfGz/o5CVMzu9o7bFcwsoB7QGrgETLmlrSkkhmF4AsuAt0QkLvs+e/yccumPXX9OImIWkdaADyoC0djWa9iDIQ8DamRb98nYZreISFjG33BgBerDuxO4khHHzIxnht/i9hQJEbmS8U9mAeZgh59TRtx1GbBQRJZnbLbbzym3/twJnxOAiMQAW4F7AW/DMDIL/xRo8+zBkO8HGmSM4roAg4FVt7hNhcYwDI+MgRoMw/AAHgaO5X+W3bAKeC7j9XPAylvYliKTaewyeBw7+5wyBtJ+BE6KyNRsu+zyc8qrP/b8ORmGUdEwDO+M16VQSR0nUQb9qYzDCvyMbvusFYCMdKKvAUfgJxH5361tUeExDKMuygsHVWpvkT32xzCMxUB3lOTmFWAC8CewBKiJkiseKCJ2MYCYR3+6o36uCxACvJottnzbYxhGF+Af4Chgydj8ASqubHefUz79eRo7/ZwMw2iJGsx0RDnWS0Tkkww78RtQDjgIPCsiqXlexx4MuUaj0Wjyxh5CKxqNRqPJB23INRqNxs7Rhlyj0WjsHG3INRqNxs7Rhlyj0WjsHG3INRqNxs7Rhlyj0WjsnP8HI157LN3BQqkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ks= [1, 4, 8, 16]\n",
    "\n",
    "data = 'cifar10'\n",
    "model = 'hopfield'\n",
    "df = pd.read_csv(f'./results/{data}_{model}_heads.csv')\n",
    "# color scheme by k\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "for i, k in enumerate(ks):\n",
    "    df_k = df[df['k'] == k]\n",
    "    # take only last 30 rows\n",
    "    df_k = df_k.iloc[-30:]\n",
    "\n",
    "    plt.plot(df_k['epoch'], df_k['accuracy'], label=f'k={k}', color=colors[i] )\n",
    "\n",
    "model = 'hopfieldV'\n",
    "df = pd.read_csv(f'./results/{data}_{model}_heads.csv')\n",
    "for i, k in enumerate(ks):\n",
    "    df_k = df[df['k'] == k]\n",
    "    # take only last 30 rows\n",
    "    df_k = df_k.iloc[30:]\n",
    "    # dash lines\n",
    "    plt.plot(df_k['epoch'], df_k['accuracy'], label=f'k={k}', linestyle='--', color=colors[i] )\n",
    "\n",
    "\n",
    "model = 'vit'\n",
    "df = pd.read_csv(f'./results/{data}_{model}_heads.csv')\n",
    "for i, k in enumerate(ks):\n",
    "    df_k = df[df['k'] == k]\n",
    "    # take only last 30 rows\n",
    "    df_k = df_k.iloc[-30:]\n",
    "    # dash lines\n",
    "    plt.plot(df_k['epoch'], df_k['accuracy'], label=f'k={k}', linestyle=':', color=colors[i] )\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k= 4\n",
    "df_k = df[df['k'] == k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows in df_k\n",
    "k =4\n",
    "df_k = df[df['k'] == k]\n",
    "df_k.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17\n",
      " 18 19 20 21 22 23 24 25 26 27 28 29  0  1  2  3  4  5  6  7  8  9 10 11\n",
      " 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  0  1  2  3  4  5\n",
      "  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n",
      "  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n"
     ]
    }
   ],
   "source": [
    "print(df_k['epoch'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcad1ab3860>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 4\n",
    "df_k = df[df['k'] == k]\n",
    "plt.plot( df_k['accuracy'].to_numpy(), label=f'k={k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph3",
   "language": "python",
   "name": "graph3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
